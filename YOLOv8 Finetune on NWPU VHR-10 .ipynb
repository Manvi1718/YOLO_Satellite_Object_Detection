{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMu+Osv/t7uyohvq3LOwluJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["# ==========================================================================\n","# CELL 1: INSTALL LIBRARIES AND MOUNT GOOGLE DRIVE\n","# ==========================================================================\n","\"\"\"\n","This cell installs all required libraries for:\n","- YOLOv8 training and inference\n","- COCO dataset handling\n","- Data preprocessing\n","- GPU acceleration\n","\"\"\"\n","# Install ultralytics (YOLOv8)\n","!pip install -q ultralytics\n","# Install additional required libraries\n","!pip install -q opencv-python pillow numpy pandas matplotlib seaborn\n","!pip install -q torch torchvision torchaudio  # PyTorch (should be pre-installed on Colab, but ensured here)\n","!pip install -q tqdm requests  # For downloading and progress tracking\n","!pip install -q scikit-learn  # For metrics calculation\n","\n","# Mount Google Drive to save dataset and models\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","print(\"‚úì All libraries installed successfully!\")\n","print(\"‚úì Google Drive mounted successfully!\")\n","\n","# Verify GPU availability\n","import torch\n","print(f\"\\n‚úì GPU Available: {torch.cuda.is_available()}\")\n","if torch.cuda.is_available():\n","    print(f\"  GPU Name: {torch.cuda.get_device_name(0)}\")\n","    print(f\"  GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"80LxYAA67W7m","executionInfo":{"status":"ok","timestamp":1762003557035,"user_tz":-330,"elapsed":33995,"user":{"displayName":"Manvi Sharma","userId":"13719445681117001639"}},"outputId":"404dbfe5-bf21-4125-cdcf-42a2f63c2c44"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","‚úì All libraries installed successfully!\n","‚úì Google Drive mounted successfully!\n","\n","‚úì GPU Available: True\n","  GPU Name: Tesla T4\n","  GPU Memory: 15.83 GB\n"]}]},{"cell_type":"code","source":["# ==========================================================================\n","# CELL 2: CREATE DIRECTORY STRUCTURE IN GOOGLE DRIVE\n","# ==========================================================================\n","\"\"\"\n","Create organized folder structure in Google Drive to store:\n","1. Raw NWPU VHR-10 dataset\n","2. Processed dataset in YOLO format\n","3. Trained models and checkpoints\n","4. Training logs and results\n","\"\"\"\n","\n","import os\n","from pathlib import Path\n","\n","# Define base directories in Google Drive\n","base_drive = '/content/drive/My Drive'\n","\n","# Create main project directory\n","project_dir = Path(base_drive) / 'YOLOv8_NWPU_VHR10'\n","project_dir.mkdir(exist_ok=True)\n","\n","# Create subdirectories\n","dataset_raw_dir = project_dir / 'NWPU_VHR-10'  # Store raw downloaded dataset\n","dataset_processed_dir = project_dir / 'NWPU_VHR-10_YOLO_Format'  # Store processed YOLO dataset\n","models_dir = project_dir / 'Models'  # Store trained models\n","results_dir = project_dir / 'Results'  # Store metrics and results\n","runs_dir = project_dir / 'Training_Runs'  # Store training logs\n","\n","# Create all directories\n","for directory in [dataset_raw_dir, dataset_processed_dir, models_dir, results_dir, runs_dir]:\n","    directory.mkdir(parents=True, exist_ok=True)\n","    print(f\"‚úì Created: {directory}\")\n","\n","# Display directory structure\n","print(\"\\n\" + \"=\"*80)\n","print(\"DIRECTORY STRUCTURE CREATED:\")\n","print(\"=\"*80)\n","print(f\"\"\"\n","{project_dir}/\n","‚îú‚îÄ‚îÄ NWPU_VHR-10/                    (Raw dataset - will be downloaded here)\n","‚îú‚îÄ‚îÄ NWPU_VHR-10_YOLO_Format/        (Processed dataset in YOLO format)\n","‚îú‚îÄ‚îÄ Models/                         (Trained model weights)\n","‚îú‚îÄ‚îÄ Results/                        (Metrics and analysis results)\n","‚îî‚îÄ‚îÄ Training_Runs/                  (Training logs and checkpoints)\n","\"\"\")\n","\n","# Define paths as variables for easy reference\n","print(f\"\\nKey Paths:\")\n","print(f\"  Raw Dataset: {dataset_raw_dir}\")\n","print(f\"  YOLO Dataset: {dataset_processed_dir}\")\n","print(f\"  Models: {models_dir}\")\n","print(f\"  Results: {results_dir}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qFMe_Okf7YVB","executionInfo":{"status":"ok","timestamp":1762003557735,"user_tz":-330,"elapsed":697,"user":{"displayName":"Manvi Sharma","userId":"13719445681117001639"}},"outputId":"7d02167a-09f3-4284-dc9e-3c403fe52c46"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úì Created: /content/drive/My Drive/YOLOv8_NWPU_VHR10/NWPU_VHR-10\n","‚úì Created: /content/drive/My Drive/YOLOv8_NWPU_VHR10/NWPU_VHR-10_YOLO_Format\n","‚úì Created: /content/drive/My Drive/YOLOv8_NWPU_VHR10/Models\n","‚úì Created: /content/drive/My Drive/YOLOv8_NWPU_VHR10/Results\n","‚úì Created: /content/drive/My Drive/YOLOv8_NWPU_VHR10/Training_Runs\n","\n","================================================================================\n","DIRECTORY STRUCTURE CREATED:\n","================================================================================\n","\n","/content/drive/My Drive/YOLOv8_NWPU_VHR10/\n","‚îú‚îÄ‚îÄ NWPU_VHR-10/                    (Raw dataset - will be downloaded here)\n","‚îú‚îÄ‚îÄ NWPU_VHR-10_YOLO_Format/        (Processed dataset in YOLO format)\n","‚îú‚îÄ‚îÄ Models/                         (Trained model weights)\n","‚îú‚îÄ‚îÄ Results/                        (Metrics and analysis results)\n","‚îî‚îÄ‚îÄ Training_Runs/                  (Training logs and checkpoints)\n","\n","\n","Key Paths:\n","  Raw Dataset: /content/drive/My Drive/YOLOv8_NWPU_VHR10/NWPU_VHR-10\n","  YOLO Dataset: /content/drive/My Drive/YOLOv8_NWPU_VHR10/NWPU_VHR-10_YOLO_Format\n","  Models: /content/drive/My Drive/YOLOv8_NWPU_VHR10/Models\n","  Results: /content/drive/My Drive/YOLOv8_NWPU_VHR10/Results\n"]}]},{"cell_type":"code","source":["# ==========================================================================\n","# CELL 3: DOWNLOAD NWPU VHR-10 DATASET\n","# ==========================================================================\n","\"\"\"\n","Download NWPU VHR-10 dataset from official sources (torchgeo)\n","Dataset Info:\n","- Total: 800 images\n","- Positive set: 650 images (contain objects)\n","- Negative set: 150 images (no objects)\n","- Classes: 10 (airplane, ship, storage tank, baseball diamond, tennis court,\n","           basketball court, ground track field, harbor, bridge, vehicle)\n","- Resolution: 0.5-2m (Google Earth), 0.08m (Vaihingen)\n","\"\"\"\n","\n","import zipfile\n","import requests\n","from tqdm import tqdm\n","import shutil\n","\n","# Path where dataset will be downloaded\n","from pathlib import Path\n","dataset_raw_dir = Path(dataset_raw_dir)\n","\n","print(\"=\"*80)\n","print(\"DOWNLOADING NWPU VHR-10 DATASET\")\n","print(\"=\"*80)\n","\n","# Download from torchgeo (official source)\n","# Note: If this link doesn't work, alternative: download from\n","# Google Cloud, Baidu Pan, or other mirrors\n","dataset_url = 'https://hf.co/datasets/torchgeo/vhr10/resolve/main/NWPU%20VHR-10%20dataset.zip'\n","annotations_url = 'https://hf.co/datasets/torchgeo/vhr10/resolve/main/annotations.json'\n","\n","# Download dataset zip file\n","dataset_zip_path = dataset_raw_dir / 'NWPU_VHR-10_dataset.zip'\n","print(f\"\\n1. Downloading dataset images (this may take 5-10 minutes)...\")\n","print(f\"   URL: {dataset_url}\")\n","print(f\"   Saving to: {dataset_zip_path}\")\n","try:\n","    # Download with progress bar\n","    response = requests.get(dataset_url, stream=True)\n","    total_size = int(response.headers.get('content-length', 0))\n","    with open(dataset_zip_path, 'wb') as f:\n","        with tqdm(total=total_size, unit='B', unit_scale=True, desc='Downloading dataset') as pbar:\n","            for chunk in response.iter_content(chunk_size=8192):\n","                f.write(chunk)\n","                pbar.update(len(chunk))\n","    print(\"‚úì Dataset download completed!\")\n","except Exception as e:\n","    print(f\"‚úó Error downloading dataset: {e}\")\n","    print(\"\\nAlternative: Download manually from:\")\n","    print(\"  - https://hf.co/datasets/torchgeo/vhr10\")\n","    print(\"  - Google Cloud Storage\")\n","    print(\"  - Baidu Pan (search NWPU VHR-10)\")\n","\n","# Download annotations JSON\n","annotations_path = dataset_raw_dir / 'annotations.json'\n","print(f\"\\n2. Downloading annotations file...\")\n","print(f\"   URL: {annotations_url}\")\n","print(f\"   Saving to: {annotations_path}\")\n","try:\n","    response = requests.get(annotations_url, stream=True)\n","    total_size = int(response.headers.get('content-length', 0))\n","    with open(annotations_path, 'wb') as f:\n","        with tqdm(total=total_size, unit='B', unit_scale=True, desc='Downloading annotations') as pbar:\n","            for chunk in response.iter_content(chunk_size=8192):\n","                f.write(chunk)\n","                pbar.update(len(chunk))\n","    print(\"‚úì Annotations download completed!\")\n","except Exception as e:\n","    print(f\"‚úó Error downloading annotations: {e}\")\n","\n","# Extract zip file\n","print(f\"\\n3. Extracting dataset (this may take 2-3 minutes)...\")\n","print(f\"   Extracting to: {dataset_raw_dir}\")\n","try:\n","    with zipfile.ZipFile(dataset_zip_path, 'r') as zip_ref:\n","        zip_ref.extractall(dataset_raw_dir)\n","    # Remove zip file to save space\n","    import os\n","    os.remove(dataset_zip_path)\n","    print(\"‚úì Dataset extraction completed!\")\n","except Exception as e:\n","    print(f\"‚úó Error extracting dataset: {e}\")\n","\n","# Verify downloaded files\n","print(f\"\\n4. Verifying downloaded files...\")\n","if annotations_path.exists():\n","    print(f\"   ‚úì Annotations: {annotations_path} ({annotations_path.stat().st_size / 1e6:.2f} MB)\")\n","\n","# List directory contents\n","print(f\"\\n5. Dataset directory contents:\")\n","for item in dataset_raw_dir.iterdir():\n","    if item.is_dir():\n","        file_count = len(list(item.glob('*')))\n","        print(f\"   üìÅ {item.name}/ ({file_count} items)\")\n","    else:\n","        print(f\"   üìÑ {item.name} ({item.stat().st_size / 1e6:.2f} MB)\")\n","\n","print(\"\\n‚úì Download and extraction completed!\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xye-5Nxw7YRj","executionInfo":{"status":"ok","timestamp":1762003579248,"user_tz":-330,"elapsed":21498,"user":{"displayName":"Manvi Sharma","userId":"13719445681117001639"}},"outputId":"6b19c209-f499-43bf-a883-ddd9cc6927d9"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["================================================================================\n","DOWNLOADING NWPU VHR-10 DATASET\n","================================================================================\n","\n","1. Downloading dataset images (this may take 5-10 minutes)...\n","   URL: https://hf.co/datasets/torchgeo/vhr10/resolve/main/NWPU%20VHR-10%20dataset.zip\n","   Saving to: /content/drive/My Drive/YOLOv8_NWPU_VHR10/NWPU_VHR-10/NWPU_VHR-10_dataset.zip\n"]},{"output_type":"stream","name":"stderr","text":["Downloading dataset: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 76.8M/76.8M [00:01<00:00, 50.6MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["‚úì Dataset download completed!\n","\n","2. Downloading annotations file...\n","   URL: https://hf.co/datasets/torchgeo/vhr10/resolve/main/annotations.json\n","   Saving to: /content/drive/My Drive/YOLOv8_NWPU_VHR10/NWPU_VHR-10/annotations.json\n"]},{"output_type":"stream","name":"stderr","text":["Downloading annotations: 1.27MB [00:00, 37.8MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["‚úì Annotations download completed!\n","\n","3. Extracting dataset (this may take 2-3 minutes)...\n","   Extracting to: /content/drive/My Drive/YOLOv8_NWPU_VHR10/NWPU_VHR-10\n","‚úì Dataset extraction completed!\n","\n","4. Verifying downloaded files...\n","   ‚úì Annotations: /content/drive/My Drive/YOLOv8_NWPU_VHR10/NWPU_VHR-10/annotations.json (1.27 MB)\n","\n","5. Dataset directory contents:\n","   üìÑ annotations.json (1.27 MB)\n","   üìÅ NWPU VHR-10 dataset/ (4 items)\n","\n","‚úì Download and extraction completed!\n"]}]},{"cell_type":"code","source":["# ==========================================================================\n","# CELL 4: CONVERT COCO FORMAT TO YOLO FORMAT (CORRECTED)\n","# ==========================================================================\n","\"\"\"\n","Convert downloaded dataset from COCO format (JSON annotations) to YOLO format\n","(text files with normalized bounding box coordinates).\n","COCO Format: {\"image_id\", \"bbox\": [x_min, y_min, width, height], \"category_id\"}\n","YOLO Format: <class_id> <x_center_norm> <y_center_norm> <width_norm> <height_norm> (normalized to 0-1)\n","\"\"\"\n","\n","import json\n","import os\n","from pathlib import Path\n","from PIL import Image\n","import numpy as np\n","import shutil  # FIX 1: Missing import!\n","\n","print(\"=\"*80)\n","print(\"CONVERTING COCO FORMAT TO YOLO FORMAT\")\n","print(\"=\"*80)\n","\n","# Paths\n","dataset_raw_dir = Path('/content/drive/My Drive/YOLOv8_NWPU_VHR10/NWPU_VHR-10')\n","dataset_processed_dir = Path('/content/drive/My Drive/YOLOv8_NWPU_VHR10/NWPU_VHR-10_YOLO_Format')\n","annotations_path = dataset_raw_dir / 'annotations.json'\n","\n","# Class mapping for NWPU VHR-10\n","# COCO format uses category_id (1-indexed)\n","class_mapping = {\n","    0: 'background',\n","    1: 'airplane',\n","    2: 'ship',\n","    3: 'storage tank',\n","    4: 'baseball diamond',\n","    5: 'tennis court',\n","    6: 'basketball court',\n","    7: 'ground track field',\n","    8: 'harbor',\n","    9: 'bridge',\n","    10: 'vehicle'\n","}\n","\n","# Load COCO annotations\n","print(\"\\n1. Loading COCO annotations...\")\n","with open(annotations_path, 'r') as f:\n","    coco_data = json.load(f)\n","print(f\"   ‚úì Loaded {len(coco_data['images'])} images\")\n","print(f\"   ‚úì Loaded {len(coco_data['annotations'])} annotations\")\n","\n","# Create category mapping (COCO ID -> class index for YOLO)\n","coco_categories = {cat['id']: idx for idx, cat in enumerate(coco_data['categories'])}\n","\n","# Create image ID to annotations mapping\n","image_annotations = {}\n","for ann in coco_data['annotations']:\n","    img_id = ann['image_id']\n","    if img_id not in image_annotations:\n","        image_annotations[img_id] = []\n","    image_annotations[img_id].append(ann)\n","\n","# FIX 2: Since you have \"NWPU VHR-10 dataset\" -> \"positive image set\"\n","# Look for this nested structure\n","print(\"\\n2. Finding positive images directory...\")\n","positive_images_dir = None\n","\n","# First try: Look for nested structure\n","nested_path = dataset_raw_dir / 'NWPU VHR-10 dataset' / 'positive image set'\n","if nested_path.exists():\n","    positive_images_dir = nested_path\n","    print(f\"   ‚úì Found positive images at: {positive_images_dir}\")\n","else:\n","    # Fallback: Search for any directory with 'positive' in name\n","    for item in dataset_raw_dir.rglob('*'):\n","        if item.is_dir() and 'positive' in item.name.lower():\n","            positive_images_dir = item\n","            print(f\"   ‚úì Found positive images at: {positive_images_dir}\")\n","            break\n","\n","if positive_images_dir is None:\n","    print(\"‚úó Could not find 'positive image set' directory\")\n","    print(\"  Available directories:\")\n","    for item in dataset_raw_dir.rglob('*'):\n","        if item.is_dir():\n","            print(f\"    - {item}\")\n","    raise Exception(\"Cannot find positive image set directory!\")\n","\n","# Convert annotations\n","print(\"\\n3. Converting annotations to YOLO format...\")\n","\n","# Create images and labels directories in YOLO format directory\n","images_dir = dataset_processed_dir / 'images'\n","labels_dir = dataset_processed_dir / 'labels'\n","images_dir.mkdir(parents=True, exist_ok=True)  # FIX 3: Added parents=True\n","labels_dir.mkdir(parents=True, exist_ok=True)\n","\n","conversion_count = 0\n","error_count = 0\n","\n","for coco_image in coco_data['images']:\n","    try:\n","        img_id = coco_image['id']\n","        img_file_name = coco_image['file_name']\n","        # FIX 4: Handle missing width/height in COCO JSON\n","        img_width = coco_image.get('width')\n","        img_height = coco_image.get('height')\n","\n","        # Find source image\n","        source_img_path = positive_images_dir / img_file_name\n","        if not source_img_path.exists():\n","            # Try with just filename (no path)\n","            if '/' in img_file_name:\n","                img_file_name = img_file_name.split('/')[-1]\n","                source_img_path = positive_images_dir / img_file_name\n","\n","        if not source_img_path.exists():\n","            print(f\"   ‚úó Image not found: {img_file_name}\")\n","            error_count += 1\n","            continue\n","\n","        # FIX 5: If dimensions missing, read from actual image\n","        if img_width is None or img_height is None:\n","            with Image.open(source_img_path) as img:\n","                img_width, img_height = img.size\n","\n","        # Copy image to processed directory\n","        dest_img_path = images_dir / img_file_name\n","        shutil.copy2(source_img_path, dest_img_path)\n","\n","        # Create YOLO format annotation\n","        yolo_annotations = []\n","        if img_id in image_annotations:\n","            for ann in image_annotations[img_id]:\n","                # Extract COCO bbox (x_min, y_min, width, height)\n","                x_min, y_min, bbox_width, bbox_height = ann['bbox']\n","                # Convert to center coordinates\n","                x_center = x_min + bbox_width / 2\n","                y_center = y_min + bbox_height / 2\n","                # Normalize to 0-1\n","                x_center_norm = x_center / img_width\n","                y_center_norm = y_center / img_height\n","                width_norm = bbox_width / img_width\n","                height_norm = bbox_height / img_height\n","                # Get YOLO class ID (0-indexed, excluding background)\n","                coco_category_id = ann['category_id']\n","                yolo_class_id = coco_categories[coco_category_id]\n","                yolo_annotations.append(f\"{yolo_class_id} {x_center_norm:.6f} {y_center_norm:.6f} {width_norm:.6f} {height_norm:.6f}\")\n","\n","        # FIX 6: Use Path.stem to get filename without extension\n","        label_file_name = Path(img_file_name).stem + '.txt'\n","        label_path = labels_dir / label_file_name\n","        with open(label_path, 'w') as f:\n","            f.write('\\n'.join(yolo_annotations))\n","\n","        conversion_count += 1\n","        if conversion_count % 100 == 0:\n","            print(f\"   ‚úì Converted {conversion_count} images...\")\n","    except Exception as e:\n","        print(f\"   ‚úó Error processing image {coco_image.get('file_name', 'unknown')}: {e}\")\n","        error_count += 1\n","\n","print(f\"\\n4. Conversion Summary:\")\n","print(f\"   ‚úì Successfully converted: {conversion_count} images\")\n","print(f\"   ‚úó Errors: {error_count}\")\n","\n","# Verify conversion\n","print(f\"\\n5. Verifying conversion...\")\n","image_files = list(images_dir.glob('*.jpg'))\n","label_files = list(labels_dir.glob('*.txt'))\n","print(f\"   ‚úì Images: {len(image_files)}\")\n","print(f\"   ‚úì Labels: {len(label_files)}\")\n","\n","# Check for mismatches\n","if len(image_files) != len(label_files):\n","    print(f\"   ‚ö† Warning: Mismatch between images ({len(image_files)}) and labels ({len(label_files)})\")\n","\n","# Display sample annotation\n","if label_files:\n","    sample_label = label_files[0]  # FIX 7: Get first label file, not list\n","    print(f\"\\n6. Sample YOLO annotation (from {sample_label.name}):\")\n","    with open(sample_label, 'r') as f:\n","        content = f.read()\n","        if content:\n","            # Show only first 3 lines\n","            lines = content.split('\\n')[:3]\n","            for line in lines:\n","                print(f\"   {line}\")\n","            if len(content.split('\\n')) > 3:\n","                print(f\"   ... ({len(content.split('\\n'))} total annotations)\")\n","        else:\n","            print(f\"   (empty - no objects)\")\n","\n","print(\"\\n\" + \"=\"*80)\n","print(\"‚úì DATASET SUCCESSFULLY CONVERTED TO YOLO FORMAT!\")\n","print(\"=\"*80)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GIedA7Eq7YPM","executionInfo":{"status":"ok","timestamp":1762003592567,"user_tz":-330,"elapsed":13321,"user":{"displayName":"Manvi Sharma","userId":"13719445681117001639"}},"outputId":"ccca7b80-0904-4d27-97e8-295a08c569e5"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["================================================================================\n","CONVERTING COCO FORMAT TO YOLO FORMAT\n","================================================================================\n","\n","1. Loading COCO annotations...\n","   ‚úì Loaded 650 images\n","   ‚úì Loaded 3921 annotations\n","\n","2. Finding positive images directory...\n","   ‚úì Found positive images at: /content/drive/My Drive/YOLOv8_NWPU_VHR10/NWPU_VHR-10/NWPU VHR-10 dataset/positive image set\n","\n","3. Converting annotations to YOLO format...\n","   ‚úì Converted 100 images...\n","   ‚úì Converted 200 images...\n","   ‚úì Converted 300 images...\n","   ‚úì Converted 400 images...\n","   ‚úì Converted 500 images...\n","   ‚úì Converted 600 images...\n","\n","4. Conversion Summary:\n","   ‚úì Successfully converted: 650 images\n","   ‚úó Errors: 0\n","\n","5. Verifying conversion...\n","   ‚úì Images: 650\n","   ‚úì Labels: 650\n","\n","6. Sample YOLO annotation (from 001.txt):\n","   0 0.622129 0.653465 0.068894 0.106436\n","\n","================================================================================\n","‚úì DATASET SUCCESSFULLY CONVERTED TO YOLO FORMAT!\n","================================================================================\n"]}]},{"cell_type":"code","source":["# ==========================================================================\n","# CELL 5: CREATE TRAIN/VAL SPLIT AND GENERATE dataset.yaml (FIXED)\n","# ==========================================================================\n","\"\"\"\n","Split the dataset into training (80%) and validation (20%) sets,\n","and create the dataset.yaml configuration file required by YOLOv8.\n","CRITICAL: YOLOv8 expects this structure:\n","  dataset/\n","    images/\n","      train/\n","      val/\n","    labels/\n","      train/\n","      val/\n","\"\"\"\n","\n","import os\n","import shutil\n","from pathlib import Path\n","import random\n","import yaml\n","\n","print(\"=\"*80)\n","print(\"CREATING TRAIN/VAL SPLIT\")\n","print(\"=\"*80)\n","\n","# Paths\n","dataset_processed_dir = Path('/content/drive/My Drive/YOLOv8_NWPU_VHR10/NWPU_VHR-10_YOLO_Format')\n","images_dir = dataset_processed_dir / 'images'\n","labels_dir = dataset_processed_dir / 'labels'\n","\n","# FIX: Create correct YOLOv8 directory structure\n","# YOLOv8 expects: dataset/images/train and dataset/labels/train (parallel structure)\n","train_images_dir = dataset_processed_dir / 'images' / 'train'\n","train_labels_dir = dataset_processed_dir / 'labels' / 'train'\n","val_images_dir = dataset_processed_dir / 'images' / 'val'\n","val_labels_dir = dataset_processed_dir / 'labels' / 'val'\n","for directory in [train_images_dir, train_labels_dir, val_images_dir, val_labels_dir]:\n","    directory.mkdir(parents=True, exist_ok=True)\n","\n","# Get all image files from the converted dataset\n","all_images = sorted(list(images_dir.glob('*.jpg')))\n","print(f\"\\nTotal images: {len(all_images)}\")\n","if len(all_images) == 0:\n","    print(\"‚úó ERROR: No images found in converted dataset!\")\n","    print(f\"  Looking in: {images_dir}\")\n","    print(\"  Please check CELL 4 conversion completed successfully\")\n","    raise Exception(\"No images found for train/val split\")\n","\n","# Split into train (80%) and val (20%)\n","random.seed(42)  # For reproducibility\n","random.shuffle(all_images)\n","split_idx = int(0.8 * len(all_images))\n","train_images = all_images[:split_idx]\n","val_images = all_images[split_idx:]\n","\n","print(f\"Training images: {len(train_images)} (80%)\")\n","print(f\"Validation images: {len(val_images)} (20%)\")\n","\n","# Copy train images and labels\n","print(\"\\n1. Copying training images and labels...\")\n","train_copied = 0\n","train_errors = 0\n","for img_path in train_images:\n","    try:\n","        # Copy image\n","        shutil.copy2(img_path, train_images_dir / img_path.name)\n","        # Copy corresponding label\n","        label_path = labels_dir / f\"{img_path.stem}.txt\"\n","        if label_path.exists():\n","            shutil.copy2(label_path, train_labels_dir / label_path.name)\n","            train_copied += 1\n","        else:\n","            print(f\"   ‚ö† Label not found for: {img_path.name}\")\n","    except Exception as e:\n","        print(f\"   ‚úó Error copying {img_path.name}: {e}\")\n","        train_errors += 1\n","\n","print(f\"   ‚úì Copied {train_copied} training image-label pairs\")\n","if train_errors > 0:\n","    print(f\"   ‚úó Errors: {train_errors}\")\n","\n","# Copy val images and labels\n","print(\"\\n2. Copying validation images and labels...\")\n","val_copied = 0\n","val_errors = 0\n","for img_path in val_images:\n","    try:\n","        # Copy image\n","        shutil.copy2(img_path, val_images_dir / img_path.name)\n","        # Copy corresponding label\n","        label_path = labels_dir / f\"{img_path.stem}.txt\"\n","        if label_path.exists():\n","            shutil.copy2(label_path, val_labels_dir / label_path.name)\n","            val_copied += 1\n","        else:\n","            print(f\"   ‚ö† Label not found for: {img_path.name}\")\n","    except Exception as e:\n","        print(f\"   ‚úó Error copying {img_path.name}: {e}\")\n","        val_errors += 1\n","\n","print(f\"   ‚úì Copied {val_copied} validation image-label pairs\")\n","if val_errors > 0:\n","    print(f\"   ‚úó Errors: {val_errors}\")\n","\n","# Define class names for NWPU VHR-10 (10 classes, 0-indexed)\n","class_names = [\n","    'airplane',\n","    'ship',\n","    'storage tank',\n","    'baseball diamond',\n","    'tennis court',\n","    'basketball court',\n","    'ground track field',\n","    'harbor',\n","    'bridge',\n","    'vehicle'\n","]\n","\n","# FIX: Create dataset.yaml with CORRECT paths for YOLOv8\n","# YOLOv8 expects paths relative to the dataset root\n","# Structure: dataset_root/images/train and dataset_root/labels/train\n","dataset_yaml = {\n","    'path': str(dataset_processed_dir),   # Dataset root directory\n","    'train': 'images/train',              # Relative path to training images\n","    'val': 'images/val',                  # Relative path to validation images\n","    'nc': len(class_names),               # Number of classes\n","    'names': class_names                  # Class names as list (0-indexed)\n","}\n","\n","yaml_path = dataset_processed_dir / 'dataset.yaml'\n","print(\"\\n3. Creating dataset.yaml...\")\n","with open(yaml_path, 'w') as f:\n","    yaml.dump(dataset_yaml, f, default_flow_style=False, sort_keys=False)\n","print(f\"   ‚úì Created: {yaml_path}\")\n","\n","# Display dataset.yaml content\n","print(\"\\n4. dataset.yaml content:\")\n","print(\"   \" + \"=\"*70)\n","with open(yaml_path, 'r') as f:\n","    content = f.read()\n","    for line in content.split('\\n'):\n","        print(f\"   {line}\")\n","print(\"   \" + \"=\"*70)\n","\n","# Verify split and structure\n","print(f\"\\n5. Verifying dataset structure...\")\n","train_img_count = len(list(train_images_dir.glob('*.jpg')))\n","train_lbl_count = len(list(train_labels_dir.glob('*.txt')))\n","val_img_count = len(list(val_images_dir.glob('*.jpg')))\n","val_lbl_count = len(list(val_labels_dir.glob('*.txt')))\n","print(f\"   Train: {train_img_count} images, {train_lbl_count} labels\")\n","print(f\"   Val: {val_img_count} images, {val_lbl_count} labels\")\n","\n","# Verify parallel structure\n","print(f\"\\n6. Verifying YOLOv8 expected structure:\")\n","expected_structure = f\"\"\"\n","{dataset_processed_dir.name}/\n","‚îú‚îÄ‚îÄ images/\n","‚îÇ   ‚îú‚îÄ‚îÄ train/ ({train_img_count} images)\n","‚îÇ   ‚îî‚îÄ‚îÄ val/ ({val_img_count} images)\n","‚îú‚îÄ‚îÄ labels/\n","‚îÇ   ‚îú‚îÄ‚îÄ train/ ({train_lbl_count} labels)\n","‚îÇ   ‚îî‚îÄ‚îÄ val/ ({val_lbl_count} labels)\n","‚îî‚îÄ‚îÄ dataset.yaml\n","\"\"\"\n","print(expected_structure)\n","\n","# Check for mismatches\n","if train_img_count != train_lbl_count:\n","    print(f\"   ‚ö† WARNING: Train mismatch! {train_img_count} images but {train_lbl_count} labels\")\n","if val_img_count != val_lbl_count:\n","    print(f\"   ‚ö† WARNING: Val mismatch! {val_img_count} images but {val_lbl_count} labels\")\n","if train_img_count == train_lbl_count and val_img_count == val_lbl_count:\n","    print(\"   ‚úì Perfect match! All images have corresponding labels\")\n","\n","# Verify at least one label has content\n","print(f\"\\n7. Verifying label content...\")\n","sample_label_list = list(train_labels_dir.glob('*.txt'))\n","if sample_label_list:\n","    sample_label = sample_label_list[0]\n","    with open(sample_label, 'r') as f:\n","        content = f.read()\n","        if content.strip():\n","            print(f\"   ‚úì Sample label ({sample_label.name}) has content:\")\n","            lines = content.strip().split('\\n')[:3]\n","            for line in lines:\n","                print(f\"     {line}\")\n","            if len(content.strip().split('\\n')) > 3:\n","                print(f\"     ... ({len(content.strip().split('\\n'))} total annotations)\")\n","        else:\n","            print(f\"   ‚ö† Sample label is empty!\")\n","else:\n","    print(\"   ‚ö† No label files found in training labels directory!\")\n","\n","print(\"\\n\" + \"=\"*80)\n","print(\"‚úì TRAIN/VAL SPLIT COMPLETED!\")\n","print(\"=\"*80)\n","print(f\"\\nDataset ready for YOLOv8 training!\")\n","print(f\"Next: Run CELL 6 to load model, then CELL 7 to train\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M1Oq0m1A7YMo","executionInfo":{"status":"ok","timestamp":1762003610293,"user_tz":-330,"elapsed":17728,"user":{"displayName":"Manvi Sharma","userId":"13719445681117001639"}},"outputId":"ad07ff1b-e9ec-4c81-add0-1592d34f59a7"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["================================================================================\n","CREATING TRAIN/VAL SPLIT\n","================================================================================\n","\n","Total images: 650\n","Training images: 520 (80%)\n","Validation images: 130 (20%)\n","\n","1. Copying training images and labels...\n","   ‚úì Copied 520 training image-label pairs\n","\n","2. Copying validation images and labels...\n","   ‚úì Copied 130 validation image-label pairs\n","\n","3. Creating dataset.yaml...\n","   ‚úì Created: /content/drive/My Drive/YOLOv8_NWPU_VHR10/NWPU_VHR-10_YOLO_Format/dataset.yaml\n","\n","4. dataset.yaml content:\n","   ======================================================================\n","   path: /content/drive/My Drive/YOLOv8_NWPU_VHR10/NWPU_VHR-10_YOLO_Format\n","   train: images/train\n","   val: images/val\n","   nc: 10\n","   names:\n","   - airplane\n","   - ship\n","   - storage tank\n","   - baseball diamond\n","   - tennis court\n","   - basketball court\n","   - ground track field\n","   - harbor\n","   - bridge\n","   - vehicle\n","   \n","   ======================================================================\n","\n","5. Verifying dataset structure...\n","   Train: 520 images, 520 labels\n","   Val: 130 images, 130 labels\n","\n","6. Verifying YOLOv8 expected structure:\n","\n","NWPU_VHR-10_YOLO_Format/\n","‚îú‚îÄ‚îÄ images/\n","‚îÇ   ‚îú‚îÄ‚îÄ train/ (520 images)\n","‚îÇ   ‚îî‚îÄ‚îÄ val/ (130 images)\n","‚îú‚îÄ‚îÄ labels/\n","‚îÇ   ‚îú‚îÄ‚îÄ train/ (520 labels)\n","‚îÇ   ‚îî‚îÄ‚îÄ val/ (130 labels)\n","‚îî‚îÄ‚îÄ dataset.yaml\n","\n","   ‚úì Perfect match! All images have corresponding labels\n","\n","7. Verifying label content...\n","   ‚úì Sample label (133.txt) has content:\n","     5 0.385311 0.504195 0.194350 0.149329\n","     5 0.548023 0.517617 0.117514 0.236577\n","     9 0.669492 0.882550 0.048588 0.033557\n","     ... (4 total annotations)\n","\n","================================================================================\n","‚úì TRAIN/VAL SPLIT COMPLETED!\n","================================================================================\n","\n","Dataset ready for YOLOv8 training!\n","Next: Run CELL 6 to load model, then CELL 7 to train\n"]}]},{"cell_type":"code","source":["# ==========================================================================\n","# CELL 5B: COMPUTE CLASS FREQUENCIES AND IDENTIFY MINORITY CLASSES\n","# ==========================================================================\n","from pathlib import Path\n","import json\n","from collections import Counter\n","import numpy as np\n","\n","dataset_processed_dir = Path('/content/drive/My Drive/YOLOv8_NWPU_VHR10/NWPU_VHR-10_YOLO_Format')\n","train_labels_dir = dataset_processed_dir / 'labels' / 'train'\n","class_names = [\n","    'airplane','ship','storage tank','baseball diamond','tennis court',\n","    'basketball court','ground track field','harbor','bridge','vehicle'\n","]\n","\n","cls_counts = Counter()\n","img_has_class = [Counter() for _ in range(len(class_names))]\n","\n","train_images_dir = dataset_processed_dir / 'images' / 'train'\n","train_images = sorted(list(train_images_dir.glob('*.jpg')))\n","\n","for img_path in train_images:\n","    lbl_path = train_labels_dir / f\"{img_path.stem}.txt\"\n","    if not lbl_path.exists():\n","        continue\n","    seen_in_image = set()\n","    with open(lbl_path, 'r') as f:\n","        for line in f:\n","            parts = line.strip().split()\n","            if len(parts) < 5:\n","                continue\n","            c = int(parts[0])\n","            cls_counts[c] += 1\n","            seen_in_image.add(c)\n","    for c in seen_in_image:\n","        img_has_class[c][img_path.name] += 1\n","\n","total_instances = sum(cls_counts.values())\n","freq = np.zeros(len(class_names), dtype=float)\n","for c in range(len(class_names)):\n","    freq[c] = cls_counts[c] / max(1, total_instances)\n","\n","print(\"Class counts:\")\n","for c in range(len(class_names)):\n","    print(f\"  {class_names[c]}: {cls_counts[c]} instances, freq={freq[c]:.6f}\")\n","\n","# Mark minority classes (e.g., below median frequency)\n","threshold = float(np.median(freq))\n","minority_classes = [c for c in range(len(class_names)) if freq[c] < threshold]\n","print(\"\\nMinority classes (below median frequency):\")\n","for c in minority_classes:\n","    print(f\"  {c} -> {class_names[c]}\")\n","\n","# Save frequencies for later cells\n","np.save(dataset_processed_dir / 'class_freq.npy', freq)\n","with open(dataset_processed_dir / 'minority_classes.json', 'w') as f:\n","    json.dump(minority_classes, f)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OqtdRNpj8NkQ","executionInfo":{"status":"ok","timestamp":1762003613718,"user_tz":-330,"elapsed":3422,"user":{"displayName":"Manvi Sharma","userId":"13719445681117001639"}},"outputId":"7271644b-6ada-4b10-d87e-6c13d9fb7711"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Class counts:\n","  airplane: 639 instances, freq=0.196434\n","  ship: 246 instances, freq=0.075623\n","  storage tank: 568 instances, freq=0.174608\n","  baseball diamond: 322 instances, freq=0.098986\n","  tennis court: 418 instances, freq=0.128497\n","  basketball court: 133 instances, freq=0.040885\n","  ground track field: 124 instances, freq=0.038119\n","  harbor: 172 instances, freq=0.052874\n","  bridge: 105 instances, freq=0.032278\n","  vehicle: 526 instances, freq=0.161697\n","\n","Minority classes (below median frequency):\n","  1 -> ship\n","  5 -> basketball court\n","  6 -> ground track field\n","  7 -> harbor\n","  8 -> bridge\n"]}]},{"cell_type":"code","source":["# ==========================================================================\n","# CELL 6: LOAD YOLOV8 MODEL (SMALL/MEDIUM VERSION)\n","# ==========================================================================\n","\"\"\"\n","Load pre-trained YOLOv8 model (Small or Medium, not Nano).\n","Available options:\n","- yolov8n.pt (Nano) - 3.01M parameters - NOT RECOMMENDED for satellite data\n","- yolov8s.pt (Small) - 11.17M parameters - RECOMMENDED\n","- yolov8m.pt (Medium) - 25.86M parameters - BETTER but slower\n","- yolov8l.pt (Large) - 43.67M parameters - BEST but requires more GPU memory\n","\"\"\"\n","\n","from ultralytics import YOLO\n","import torch\n","\n","print(\"=\"*80)\n","print(\"LOADING YOLOV8 MODEL\")\n","print(\"=\"*80)\n","\n","# Check GPU memory\n","if torch.cuda.is_available():\n","    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n","    print(f\"\\n‚úì GPU Memory Available: {gpu_memory:.2f} GB\")\n","    # Recommend model based on GPU memory\n","    if gpu_memory >= 16:\n","        recommended_model = 'yolov8m.pt'\n","        print(\"  Recommendation: YOLOv8 Medium (good for satellite data with more capacity)\")\n","    else:\n","        recommended_model = 'yolov8s.pt'\n","        print(\"  Recommendation: YOLOv8 Small (balanced for limited GPU)\")\n","else:\n","    recommended_model = 'yolov8s.pt'\n","    print(\"\\n‚ö† GPU not available! Consider using Google Colab with GPU\")\n","\n","# Select model\n","# CHANGE THIS IF YOU WANT DIFFERENT SIZE\n","model_choice = 'yolov8s.pt'  # Options: yolov8n.pt, yolov8s.pt, yolov8m.pt, yolov8l.pt\n","print(f\"\\n1. Loading YOLOv8 model: {model_choice}\")\n","print(\"   Downloading pre-trained weights (first time only)...\")\n","\n","# Load model - ultralytics will automatically download weights\n","model = YOLO(model_choice)\n","print(f\"\\n2. Model loaded successfully!\")\n","print(f\"   ‚úì Model: {model_choice}\")\n","\n","# Display model information\n","print(f\"\\n3. Model Information:\")\n","print(f\"   Total parameters: {sum(p.numel() for p in model.model.parameters())}\")\n","print(f\"   Trainable parameters: {sum(p.numel() for p in model.model.parameters() if p.requires_grad)}\")\n","\n","# Display model summary\n","print(f\"\\n4. Model Architecture Summary:\")\n","print(f\"   {model.model}\")\n","\n","# Verify model is on GPU\n","if next(model.model.parameters()).is_cuda:\n","    print(f\"\\n‚úì Model loaded on GPU\")\n","else:\n","    print(f\"\\n‚ö† Model loaded on CPU (training will be slow)\")\n","\n","print(\"\\n‚úì Model loaded successfully!\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XKL0yqjS7YKK","executionInfo":{"status":"ok","timestamp":1762003614211,"user_tz":-330,"elapsed":479,"user":{"displayName":"Manvi Sharma","userId":"13719445681117001639"}},"outputId":"03f60f34-0d13-42a0-9193-e86300a71f74"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Creating new Ultralytics Settings v0.0.6 file ‚úÖ \n","View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n","Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n","================================================================================\n","LOADING YOLOV8 MODEL\n","================================================================================\n","\n","‚úì GPU Memory Available: 15.83 GB\n","  Recommendation: YOLOv8 Small (balanced for limited GPU)\n","\n","1. Loading YOLOv8 model: yolov8s.pt\n","   Downloading pre-trained weights (first time only)...\n","\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8s.pt to 'yolov8s.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21.5MB 337.8MB/s 0.1s\n","\n","2. Model loaded successfully!\n","   ‚úì Model: yolov8s.pt\n","\n","3. Model Information:\n","   Total parameters: 11166560\n","   Trainable parameters: 0\n","\n","4. Model Architecture Summary:\n","   DetectionModel(\n","  (model): Sequential(\n","    (0): Conv(\n","      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","      (act): SiLU(inplace=True)\n","    )\n","    (1): Conv(\n","      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","      (act): SiLU(inplace=True)\n","    )\n","    (2): C2f(\n","      (cv1): Conv(\n","        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","      (cv2): Conv(\n","        (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","      (m): ModuleList(\n","        (0): Bottleneck(\n","          (cv1): Conv(\n","            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","          (cv2): Conv(\n","            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","        )\n","      )\n","    )\n","    (3): Conv(\n","      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","      (act): SiLU(inplace=True)\n","    )\n","    (4): C2f(\n","      (cv1): Conv(\n","        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","      (cv2): Conv(\n","        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","      (m): ModuleList(\n","        (0-1): 2 x Bottleneck(\n","          (cv1): Conv(\n","            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","          (cv2): Conv(\n","            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","        )\n","      )\n","    )\n","    (5): Conv(\n","      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","      (act): SiLU(inplace=True)\n","    )\n","    (6): C2f(\n","      (cv1): Conv(\n","        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","      (cv2): Conv(\n","        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","      (m): ModuleList(\n","        (0-1): 2 x Bottleneck(\n","          (cv1): Conv(\n","            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","          (cv2): Conv(\n","            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","        )\n","      )\n","    )\n","    (7): Conv(\n","      (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","      (act): SiLU(inplace=True)\n","    )\n","    (8): C2f(\n","      (cv1): Conv(\n","        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","      (cv2): Conv(\n","        (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","      (m): ModuleList(\n","        (0): Bottleneck(\n","          (cv1): Conv(\n","            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","          (cv2): Conv(\n","            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","        )\n","      )\n","    )\n","    (9): SPPF(\n","      (cv1): Conv(\n","        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","      (cv2): Conv(\n","        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","      (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n","    )\n","    (10): Upsample(scale_factor=2.0, mode='nearest')\n","    (11): Concat()\n","    (12): C2f(\n","      (cv1): Conv(\n","        (conv): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","      (cv2): Conv(\n","        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","      (m): ModuleList(\n","        (0): Bottleneck(\n","          (cv1): Conv(\n","            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","          (cv2): Conv(\n","            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","        )\n","      )\n","    )\n","    (13): Upsample(scale_factor=2.0, mode='nearest')\n","    (14): Concat()\n","    (15): C2f(\n","      (cv1): Conv(\n","        (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","      (cv2): Conv(\n","        (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","      (m): ModuleList(\n","        (0): Bottleneck(\n","          (cv1): Conv(\n","            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","          (cv2): Conv(\n","            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","        )\n","      )\n","    )\n","    (16): Conv(\n","      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","      (act): SiLU(inplace=True)\n","    )\n","    (17): Concat()\n","    (18): C2f(\n","      (cv1): Conv(\n","        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","      (cv2): Conv(\n","        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","      (m): ModuleList(\n","        (0): Bottleneck(\n","          (cv1): Conv(\n","            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","          (cv2): Conv(\n","            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","        )\n","      )\n","    )\n","    (19): Conv(\n","      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","      (act): SiLU(inplace=True)\n","    )\n","    (20): Concat()\n","    (21): C2f(\n","      (cv1): Conv(\n","        (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","      (cv2): Conv(\n","        (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","      (m): ModuleList(\n","        (0): Bottleneck(\n","          (cv1): Conv(\n","            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","          (cv2): Conv(\n","            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","        )\n","      )\n","    )\n","    (22): Detect(\n","      (cv2): ModuleList(\n","        (0): Sequential(\n","          (0): Conv(\n","            (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","          (1): Conv(\n","            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","          (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n","        )\n","        (1): Sequential(\n","          (0): Conv(\n","            (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","          (1): Conv(\n","            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","          (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n","        )\n","        (2): Sequential(\n","          (0): Conv(\n","            (conv): Conv2d(512, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","          (1): Conv(\n","            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","          (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n","        )\n","      )\n","      (cv3): ModuleList(\n","        (0): Sequential(\n","          (0): Conv(\n","            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","          (1): Conv(\n","            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","          (2): Conv2d(128, 80, kernel_size=(1, 1), stride=(1, 1))\n","        )\n","        (1): Sequential(\n","          (0): Conv(\n","            (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","          (1): Conv(\n","            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","          (2): Conv2d(128, 80, kernel_size=(1, 1), stride=(1, 1))\n","        )\n","        (2): Sequential(\n","          (0): Conv(\n","            (conv): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","          (1): Conv(\n","            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","          (2): Conv2d(128, 80, kernel_size=(1, 1), stride=(1, 1))\n","        )\n","      )\n","      (dfl): DFL(\n","        (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      )\n","    )\n","  )\n",")\n","\n","‚ö† Model loaded on CPU (training will be slow)\n","\n","‚úì Model loaded successfully!\n"]}]},{"cell_type":"code","source":["# ==========================================================================\n","# REBUILD train_expanded_list.txt FROM CURRENT TRAIN SPLIT\n","# (Run this BEFORE your materialize cell)\n","# ==========================================================================\n","from pathlib import Path\n","import numpy as np\n","import math\n","import json\n","\n","dataset_processed_dir = Path('/content/drive/My Drive/YOLOv8_NWPU_VHR10/NWPU_VHR-10_YOLO_Format')\n","train_images_dir = dataset_processed_dir / 'images' / 'train'\n","train_labels_dir = dataset_processed_dir / 'labels' / 'train'\n","\n","# If you previously computed class frequencies, load them; otherwise compute quickly here\n","class_names = [\n","    'airplane','ship','storage tank','baseball diamond','tennis court',\n","    'basketball court','ground track field','harbor','bridge','vehicle'\n","]\n","C = len(class_names)\n","\n","# Compute class frequencies from labels\n","cls_counts = [0]*C\n","total_instances = 0\n","for img_path in sorted(train_images_dir.glob('*.jpg')):\n","    lbl_path = train_labels_dir / f\"{img_path.stem}.txt\"\n","    if not lbl_path.exists():\n","        continue\n","    with open(lbl_path, 'r') as f:\n","        for line in f:\n","            parts = line.strip().split()\n","            if len(parts) < 5:\n","                continue\n","            c = int(parts[0])\n","            if 0 <= c < C:\n","                cls_counts[c] += 1\n","                total_instances += 1\n","\n","freq = np.array([(cnt / total_instances) if total_instances > 0 else 0.0 for cnt in cls_counts], dtype=float)\n","print(\"Class frequencies:\", freq)\n","\n","# Repeat-Factor parameters\n","t = 0.005\n","\n","def repeat_factor_for_class(fc):\n","    if fc <= 0:\n","        return 1.0\n","    return max(1.0, math.sqrt(t / fc))\n","\n","class_rf = [repeat_factor_for_class(fc) for fc in freq]\n","\n","# Build expanded list\n","expanded = []\n","for img_path in sorted(train_images_dir.glob('*.jpg')):\n","    lbl_path = train_labels_dir / f\"{img_path.stem}.txt\"\n","    if not lbl_path.exists():\n","        continue\n","    present = set()\n","    with open(lbl_path, 'r') as f:\n","        for line in f:\n","            parts = line.strip().split()\n","            if len(parts) < 5:\n","                continue\n","            c = int(parts[0])\n","            if 0 <= c < C:\n","                present.add(c)\n","    rf_img = max([class_rf[c] for c in present], default=1.0)\n","    k = int(math.floor(rf_img))\n","    p = rf_img - k\n","    reps = k + (1 if np.random.rand() < p else 0)\n","    reps = max(1, reps)\n","    expanded.extend([img_path.name]*reps)\n","\n","expanded_list_path = dataset_processed_dir / 'train_expanded_list.txt'\n","with open(expanded_list_path, 'w') as f:\n","    for name in expanded:\n","        f.write(name + '\\n')\n","\n","print(f\"Saved: {expanded_list_path} | entries={len(expanded)} | unique={len(set(expanded))}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OLyvMYINBNwc","executionInfo":{"status":"ok","timestamp":1762003617190,"user_tz":-330,"elapsed":2978,"user":{"displayName":"Manvi Sharma","userId":"13719445681117001639"}},"outputId":"9fea0c2d-61b6-4421-d903-13e08148169c"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Class frequencies: [    0.19643    0.075623     0.17461    0.098986      0.1285    0.040885    0.038119    0.052874    0.032278      0.1617]\n","Saved: /content/drive/My Drive/YOLOv8_NWPU_VHR10/NWPU_VHR-10_YOLO_Format/train_expanded_list.txt | entries=520 | unique=520\n"]}]},{"cell_type":"code","source":["# ==========================================================================\n","# CELL 6B (ALTERNATIVE): MATERIALIZE REPEATED TRAIN SPLIT\n","# ==========================================================================\n","from pathlib import Path\n","import shutil\n","\n","dataset_processed_dir = Path('/content/drive/My Drive/YOLOv8_NWPU_VHR10/NWPU_VHR-10_YOLO_Format')\n","train_images_dir = dataset_processed_dir / 'images' / 'train'\n","train_labels_dir = dataset_processed_dir / 'labels' / 'train'\n","\n","bal_images_dir = dataset_processed_dir / 'images' / 'train_bal'\n","bal_labels_dir = dataset_processed_dir / 'labels' / 'train_bal'\n","bal_images_dir.mkdir(parents=True, exist_ok=True)\n","bal_labels_dir.mkdir(parents=True, exist_ok=True)\n","\n","expanded_list_path = dataset_processed_dir / 'train_expanded_list.txt'\n","with open(expanded_list_path, 'r') as f:\n","    expanded_train_names = [line.strip() for line in f if line.strip()]\n","\n","# Populate balanced split by copying with unique suffixes\n","counter = {}\n","for name in expanded_train_names:\n","    stem = Path(name).stem\n","    counter[stem] = counter.get(stem, 0) + 1\n","    k = counter[stem]\n","    src_img = train_images_dir / name\n","    src_lbl = train_labels_dir / f\"{stem}.txt\"\n","    if not src_img.exists() or not src_lbl.exists():\n","        continue\n","    dst_img = bal_images_dir / f\"{stem}__rep{k}.jpg\"\n","    dst_lbl = bal_labels_dir / f\"{stem}__rep{k}.txt\"\n","    shutil.copy2(src_img, dst_img)\n","    shutil.copy2(src_lbl, dst_lbl)\n","\n","print(f\"Balanced train images: {len(list(bal_images_dir.glob('*.jpg')))}\")\n","print(f\"Balanced train labels: {len(list(bal_labels_dir.glob('*.txt')))}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eV8O7ruW7qrq","executionInfo":{"status":"ok","timestamp":1762003631290,"user_tz":-330,"elapsed":14098,"user":{"displayName":"Manvi Sharma","userId":"13719445681117001639"}},"outputId":"41735c94-d5b3-4dd3-d2f3-6053e0a1c096"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Balanced train images: 520\n","Balanced train labels: 520\n"]}]},{"cell_type":"code","source":["# ==========================================================================\n","# CELL 7 (ALTERNATIVE): TRAIN USING MATERIALIZED BALANCED SPLIT\n","# ==========================================================================\n","from ultralytics import YOLO\n","from pathlib import Path\n","import yaml\n","import shutil\n","\n","dataset_processed_dir = Path('/content/drive/My Drive/YOLOv8_NWPU_VHR10/NWPU_VHR-10_YOLO_Format')\n","yaml_path = dataset_processed_dir / 'dataset.yaml'\n","with open(yaml_path, 'r') as f:\n","    ds_cfg = yaml.safe_load(f)\n","\n","# Create a temporary yaml that uses the balanced train split\n","tmp_yaml = dataset_processed_dir / 'dataset_balanced.yaml'\n","ds_bal = dict(ds_cfg)\n","ds_bal['train'] = 'images/train_bal'  # use balanced split\n","ds_bal['val'] = 'images/val'          # keep validation untouched\n","with open(tmp_yaml, 'w') as f:\n","    yaml.safe_dump(ds_bal, f, sort_keys=False)\n","\n","models_dir = Path('/content/drive/My Drive/YOLOv8_NWPU_VHR10/Models')\n","runs_dir = Path('/content/drive/My Drive/YOLOv8_NWPU_VHR10/Training_Runs')\n","\n","model = YOLO('yolov8s.pt')\n","results = model.train(\n","    data=str(tmp_yaml),\n","    epochs=120,\n","    imgsz=640,\n","    batch=16,\n","    patience=40,\n","    device=0,\n","\n","    lr0=0.001,\n","    lrf=0.01,\n","    momentum=0.937,\n","    weight_decay=0.0005,\n","    optimizer='SGD',\n","    warmup_epochs=5,\n","    warmup_momentum=0.8,\n","    warmup_bias_lr=0.1,\n","\n","    mosaic=1.0,\n","    mixup=0.15,\n","    copy_paste=0.3,\n","    degrees=45,\n","    translate=0.15,\n","    scale=0.5,\n","    flipud=0.5,\n","    fliplr=0.5,\n","    perspective=0.0001,\n","    hsv_h=0.015,\n","    hsv_s=0.7,\n","    hsv_v=0.4,\n","\n","    save=True,\n","    save_period=10,\n","    val=True,\n","    verbose=True,\n","    project=str(runs_dir),\n","    name='NWPU_VHR10_yolov8s_balanced_materialized',\n","    exist_ok=False,\n",")\n","\n","print(\"\\nTraining finished.\")\n","best_model_path = Path(results.save_dir) / 'weights' / 'best.pt'\n","if best_model_path.exists():\n","    dest = models_dir / 'yolov8s_nwpu_vhr_10_best_balanced.pt'\n","    shutil.copy2(best_model_path, dest)\n","    print(f\"Saved best model: {dest}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NT7PQ_Yk_jDd","executionInfo":{"status":"ok","timestamp":1762005760208,"user_tz":-330,"elapsed":1784299,"user":{"displayName":"Manvi Sharma","userId":"13719445681117001639"}},"outputId":"7dee3b31-45c0-4c97-ea04-f6130af41d49"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics 8.3.223 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.3, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/My Drive/YOLOv8_NWPU_VHR10/NWPU_VHR-10_YOLO_Format/dataset_balanced.yaml, degrees=45, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=120, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.5, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.15, mode=train, model=yolov8s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=NWPU_VHR10_yolov8s_balanced_materialized, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=40, perspective=0.0001, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/My Drive/YOLOv8_NWPU_VHR10/Training_Runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/My Drive/YOLOv8_NWPU_VHR10/Training_Runs/NWPU_VHR10_yolov8s_balanced_materialized, save_frames=False, save_json=False, save_period=10, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.15, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=5, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 755.1KB 99.8MB/s 0.0s\n","Overriding model.yaml nc=80 with nc=10\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2119918  ultralytics.nn.modules.head.Detect           [10, [128, 256, 512]]         \n","Model summary: 129 layers, 11,139,470 parameters, 11,139,454 gradients, 28.7 GFLOPs\n","\n","Transferred 349/355 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5.4MB 255.1MB/s 0.0s\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.5¬±0.2 ms, read: 48.9¬±12.4 MB/s, size: 86.9 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/My Drive/YOLOv8_NWPU_VHR10/NWPU_VHR-10_YOLO_Format/labels/train_bal... 520 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 520/520 89.7it/s 5.8s\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/My Drive/YOLOv8_NWPU_VHR10/NWPU_VHR-10_YOLO_Format/labels/train_bal.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 1.6¬±0.8 ms, read: 10.6¬±12.0 MB/s, size: 85.3 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/My Drive/YOLOv8_NWPU_VHR10/NWPU_VHR-10_YOLO_Format/labels/val... 130 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 130/130 49.9it/s 2.6s\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/My Drive/YOLOv8_NWPU_VHR10/NWPU_VHR-10_YOLO_Format/labels/val.cache\n","Plotting labels to /content/drive/My Drive/YOLOv8_NWPU_VHR10/Training_Runs/NWPU_VHR10_yolov8s_balanced_materialized/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.001, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/content/drive/My Drive/YOLOv8_NWPU_VHR10/Training_Runs/NWPU_VHR10_yolov8s_balanced_materialized\u001b[0m\n","Starting training for 120 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      1/120      4.09G      2.657      5.747       2.08        101        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.1it/s 15.8s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 1.1it/s 4.5s\n","                   all        130        668      0.165      0.128     0.0656     0.0482\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      2/120      4.64G      2.474      4.138      1.955        136        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.4it/s 13.7s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.3it/s 2.2s\n","                   all        130        668      0.338      0.282      0.232      0.136\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      3/120      4.67G      2.218       2.88      1.793         84        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.4it/s 13.6s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.0it/s 2.5s\n","                   all        130        668      0.744      0.377      0.383      0.209\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      4/120      4.69G      2.055      2.437      1.702         84        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.4it/s 13.8s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.8it/s 1.8s\n","                   all        130        668      0.766      0.462      0.467      0.196\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      5/120      4.71G      1.887      2.008      1.547        105        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.3it/s 14.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.6it/s 1.9s\n","                   all        130        668      0.837      0.441      0.528      0.244\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      6/120      4.74G      1.779      1.832      1.503        160        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.4it/s 14.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.2it/s 1.6s\n","                   all        130        668      0.671      0.562      0.569      0.221\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      7/120      4.76G      1.696      1.666      1.458         73        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.3it/s 14.5s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.9it/s 1.7s\n","                   all        130        668      0.719      0.635      0.657      0.256\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      8/120      4.79G      1.615      1.593        1.4        130        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.4it/s 13.8s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 1.9it/s 2.7s\n","                   all        130        668      0.727      0.685      0.669       0.28\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      9/120      4.81G      1.604      1.516      1.418         67        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.2it/s 14.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.4it/s 1.5s\n","                   all        130        668      0.735      0.659      0.671      0.279\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     10/120      4.84G      1.522      1.341      1.336         80        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.3it/s 14.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.0it/s 1.6s\n","                   all        130        668      0.697       0.69      0.697      0.305\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     11/120      4.86G       1.49      1.275      1.343         85        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.4it/s 13.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.0it/s 1.7s\n","                   all        130        668      0.774      0.679      0.717      0.317\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     12/120      4.88G      1.495       1.24      1.314         91        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.3it/s 14.1s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.8it/s 1.8s\n","                   all        130        668      0.693      0.687      0.717       0.31\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     13/120      4.91G      1.454       1.18      1.294        105        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.3it/s 14.4s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.0it/s 2.4s\n","                   all        130        668      0.697      0.772      0.752      0.351\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     14/120      4.93G      1.434      1.123      1.287         96        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.2it/s 14.8s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.2it/s 1.6s\n","                   all        130        668      0.694       0.78      0.745      0.367\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     15/120      4.96G       1.45      1.151       1.27         76        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.3it/s 14.4s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.8it/s 1.8s\n","                   all        130        668      0.755      0.756      0.765      0.397\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     16/120      4.98G       1.41      1.142      1.294         55        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.3it/s 14.4s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.8it/s 1.8s\n","                   all        130        668      0.745      0.758      0.767      0.404\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     17/120         5G      1.354      1.033      1.231        155        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.5it/s 13.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.4it/s 2.1s\n","                   all        130        668      0.777      0.769      0.791      0.417\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     18/120      5.03G      1.419      1.092      1.262        112        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.3it/s 14.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.5it/s 2.0s\n","                   all        130        668      0.772       0.81      0.811       0.42\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     19/120      5.05G       1.35      1.013      1.249        113        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.4it/s 13.7s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.4it/s 1.5s\n","                   all        130        668      0.822      0.803      0.841      0.465\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     20/120      5.08G      1.351      1.032      1.233        119        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.2it/s 14.7s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.4it/s 1.5s\n","                   all        130        668      0.803      0.813      0.842      0.488\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     21/120       5.1G      1.353      1.039      1.243        112        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.3it/s 14.1s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.1it/s 1.6s\n","                   all        130        668      0.797      0.843      0.846      0.461\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     22/120      5.13G      1.339     0.9637      1.206        172        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.3it/s 14.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.0it/s 2.4s\n","                   all        130        668      0.832      0.835      0.873      0.487\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     23/120      5.15G      1.327     0.9682      1.212        109        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.3it/s 14.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.6it/s 1.9s\n","                   all        130        668      0.807      0.857      0.862      0.507\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     24/120      5.18G      1.337     0.9768      1.211        163        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.3it/s 14.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.1it/s 1.6s\n","                   all        130        668      0.841      0.849      0.877      0.533\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     25/120       5.2G        1.3     0.9468      1.195         85        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.4it/s 14.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.8it/s 1.8s\n","                   all        130        668      0.832      0.852      0.882      0.547\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     26/120      5.22G      1.303     0.9405      1.203         57        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.5it/s 13.4s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.1it/s 2.4s\n","                   all        130        668      0.854      0.835      0.884      0.535\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     27/120      5.25G      1.342      0.947      1.213        133        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.4it/s 14.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.1it/s 1.6s\n","                   all        130        668      0.844      0.868       0.88      0.534\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     28/120      5.27G      1.291     0.9247      1.177         99        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.3it/s 14.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.9it/s 1.7s\n","                   all        130        668       0.85       0.89      0.896      0.556\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     29/120      5.29G      1.274     0.9098      1.195         59        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.4it/s 13.7s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.9it/s 1.7s\n","                   all        130        668       0.83      0.856      0.868       0.54\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     30/120      5.32G      1.295     0.8909      1.173        103        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.3it/s 14.1s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.3it/s 2.2s\n","                   all        130        668      0.842      0.872      0.878      0.563\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     31/120      5.35G      1.261     0.8789      1.166         94        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.5it/s 13.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.2it/s 2.2s\n","                   all        130        668      0.875      0.888      0.912      0.592\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     32/120      5.37G      1.294     0.9087      1.203         85        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.4it/s 13.6s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.0it/s 1.7s\n","                   all        130        668      0.858      0.883      0.907      0.606\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     33/120      5.39G      1.269     0.8769      1.183        150        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.4it/s 14.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.5it/s 2.0s\n","                   all        130        668      0.852      0.879      0.909      0.605\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     34/120      5.42G      1.267     0.9075      1.182        125        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.1it/s 15.5s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.0it/s 1.7s\n","                   all        130        668      0.858      0.883      0.916      0.594\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     35/120      5.44G      1.259      0.866      1.177        149        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.1it/s 15.6s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.6it/s 1.9s\n","                   all        130        668      0.877      0.882      0.907      0.595\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     36/120      5.47G       1.23     0.8354       1.15        106        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.3it/s 14.5s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.1it/s 1.6s\n","                   all        130        668      0.881      0.881      0.908      0.618\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     37/120      5.49G      1.313     0.9164      1.199         96        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.0it/s 16.6s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.5it/s 2.0s\n","                   all        130        668      0.871      0.887      0.902      0.607\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     38/120      5.52G      1.225     0.8206      1.136        157        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.2it/s 14.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.5it/s 2.0s\n","                   all        130        668      0.899      0.873      0.909      0.617\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     39/120      5.54G      1.246     0.8524      1.157        128        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.1it/s 15.8s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.1it/s 1.6s\n","                   all        130        668      0.876      0.885      0.914       0.63\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     40/120      5.57G      1.269     0.8573      1.153        127        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.0it/s 16.7s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 1.9it/s 2.6s\n","                   all        130        668      0.888       0.89      0.926      0.646\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     41/120      5.59G      1.267     0.8579      1.159         86        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.0it/s 16.5s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.6it/s 1.4s\n","                   all        130        668      0.851      0.899      0.914      0.641\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     42/120      5.62G      1.237     0.8318      1.158         78        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.0it/s 16.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.0it/s 1.6s\n","                   all        130        668      0.869      0.888      0.915      0.627\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     43/120      5.64G       1.19     0.8003      1.127        147        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.1it/s 15.4s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 1.8it/s 2.8s\n","                   all        130        668      0.856      0.899      0.907       0.59\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     44/120      5.66G      1.204     0.8109      1.129         82        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.1it/s 15.8s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.8it/s 1.8s\n","                   all        130        668      0.915      0.904       0.92      0.604\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     45/120      5.68G      1.196     0.7968      1.147         78        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.2it/s 15.1s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.7it/s 1.8s\n","                   all        130        668      0.897      0.904       0.92      0.601\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     46/120      5.97G      1.204     0.7944       1.12         54        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.2it/s 15.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.3it/s 2.2s\n","                   all        130        668      0.891      0.885      0.913      0.598\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     47/120         6G      1.204     0.7902       1.14        107        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.1it/s 15.6s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.6it/s 1.9s\n","                   all        130        668       0.89      0.908      0.913      0.611\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     48/120      6.02G        1.2     0.7934      1.131        100        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.2it/s 14.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.8it/s 1.8s\n","                   all        130        668      0.887      0.884      0.913      0.641\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     49/120      6.04G      1.196     0.7917      1.147         87        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.2it/s 15.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.4it/s 2.1s\n","                   all        130        668      0.897       0.88      0.909      0.629\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     50/120      6.07G      1.178     0.7663      1.124        137        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.1it/s 15.5s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.0it/s 1.7s\n","                   all        130        668        0.9      0.904      0.927      0.645\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     51/120      6.09G      1.217     0.7917      1.138         73        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.1it/s 15.6s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.3it/s 1.5s\n","                   all        130        668      0.898        0.9      0.923      0.638\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     52/120      6.12G      1.213     0.8113      1.132        141        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.1it/s 15.6s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.0it/s 1.7s\n","                   all        130        668      0.866      0.918      0.922      0.635\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     53/120      6.46G      1.182     0.7829      1.126         81        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.1it/s 15.4s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.4it/s 2.0s\n","                   all        130        668      0.888      0.917      0.931      0.638\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     54/120      6.49G      1.202     0.7869      1.135         42        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.1it/s 15.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.1it/s 1.6s\n","                   all        130        668      0.892      0.898      0.921      0.647\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     55/120      6.51G      1.164      0.766      1.121         78        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.1it/s 15.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.4it/s 2.1s\n","                   all        130        668      0.895      0.907      0.931      0.644\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     56/120      6.54G      1.171     0.7549      1.105         92        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.1it/s 16.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.9it/s 1.7s\n","                   all        130        668      0.895        0.9      0.927      0.656\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     57/120      6.56G      1.185     0.7673      1.123        102        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.0it/s 16.5s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.8it/s 1.8s\n","                   all        130        668      0.903      0.901      0.923       0.65\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     58/120      6.58G      1.178     0.7539      1.126         90        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.3it/s 14.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.2it/s 2.2s\n","                   all        130        668      0.885      0.911      0.926      0.651\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     59/120      6.61G      1.166      0.766      1.116        175        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.2it/s 15.1s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.5it/s 2.0s\n","                   all        130        668        0.9      0.909      0.922      0.648\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     60/120      6.63G      1.139     0.7412      1.114         92        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.2it/s 15.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.7it/s 1.8s\n","                   all        130        668      0.904      0.907      0.919      0.631\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     61/120      6.65G      1.218     0.7867      1.131        107        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.2it/s 15.1s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.0it/s 1.6s\n","                   all        130        668      0.893      0.901       0.92      0.628\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     62/120      6.68G      1.157     0.7271      1.118        110        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.1it/s 15.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.1it/s 2.3s\n","                   all        130        668      0.894      0.901      0.922      0.638\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     63/120      6.71G       1.16     0.7422      1.119        103        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.1it/s 15.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.0it/s 1.7s\n","                   all        130        668      0.899      0.905      0.935      0.669\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     64/120      6.73G      1.176     0.7579      1.123        132        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.0it/s 16.6s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.9it/s 1.7s\n","                   all        130        668      0.897      0.895       0.93      0.659\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     65/120      6.75G      1.193     0.7399      1.106        105        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.1it/s 15.7s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.7it/s 1.8s\n","                   all        130        668      0.902      0.899      0.936      0.668\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     66/120      6.78G      1.173     0.7572      1.125         86        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.1it/s 15.5s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.8it/s 1.8s\n","                   all        130        668       0.89      0.905      0.921       0.65\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     67/120       6.8G      1.187     0.7649       1.13        112        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.2it/s 15.1s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.0it/s 1.6s\n","                   all        130        668      0.897      0.893      0.919      0.655\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     68/120      6.83G      1.154     0.7143      1.098         82        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.1it/s 15.6s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.0it/s 2.6s\n","                   all        130        668      0.921      0.885      0.927      0.658\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     69/120      6.85G      1.158     0.7521      1.105         84        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.1it/s 15.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.2it/s 1.6s\n","                   all        130        668      0.923      0.893      0.931      0.662\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     70/120      6.88G      1.138     0.7469      1.112         74        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.2it/s 15.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.1it/s 1.6s\n","                   all        130        668      0.896      0.892      0.926      0.664\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     71/120       6.9G      1.141      0.733      1.101         90        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.1it/s 15.4s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.0it/s 2.5s\n","                   all        130        668       0.91      0.911      0.933      0.665\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     72/120      6.93G      1.134      0.712      1.099        155        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.2it/s 15.1s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.6it/s 1.9s\n","                   all        130        668      0.905      0.923      0.938      0.667\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     73/120      6.95G       1.12     0.7119      1.105         75        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.2it/s 15.1s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.7it/s 1.8s\n","                   all        130        668      0.902      0.936      0.937      0.662\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     74/120      6.97G      1.149     0.7388      1.122         52        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.1it/s 15.5s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.1it/s 2.4s\n","                   all        130        668      0.902      0.916      0.938      0.663\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     75/120         7G      1.156     0.7404      1.111         47        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.2it/s 15.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.1it/s 1.6s\n","                   all        130        668      0.893       0.93      0.937      0.684\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     76/120      7.02G      1.181      0.729      1.108        141        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.0it/s 16.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.9it/s 1.7s\n","                   all        130        668      0.911      0.913      0.927      0.673\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     77/120      7.04G      1.164     0.7333      1.122         56        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.3it/s 14.7s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.2it/s 2.3s\n","                   all        130        668      0.883      0.923       0.92      0.661\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     78/120      7.07G      1.162     0.7381      1.115         60        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.1it/s 15.7s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.8it/s 1.8s\n","                   all        130        668      0.887      0.923      0.925      0.674\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     79/120       7.1G      1.133     0.7271      1.098        115        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.1it/s 15.5s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.9it/s 1.7s\n","                   all        130        668      0.887      0.915      0.928      0.675\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     80/120      7.12G      1.122     0.7001      1.083        121        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.2it/s 15.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.6it/s 1.9s\n","                   all        130        668      0.887      0.912      0.928      0.669\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     81/120      7.14G      1.118     0.6979      1.088         67        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.1it/s 15.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.1it/s 1.6s\n","                   all        130        668      0.902      0.903      0.924      0.668\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     82/120      7.17G      1.116     0.6875      1.088        151        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.2it/s 15.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.0it/s 1.7s\n","                   all        130        668      0.903      0.907      0.926      0.667\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     83/120      7.19G      1.134     0.7139      1.109         75        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.2it/s 15.1s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.6it/s 1.9s\n","                   all        130        668      0.907      0.915       0.93      0.663\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     84/120      7.48G      1.081     0.6703      1.067         92        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.2it/s 14.8s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.0it/s 1.7s\n","                   all        130        668        0.9      0.909      0.926      0.668\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     85/120      4.13G      1.121     0.6981      1.089        181        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.3it/s 14.4s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.1it/s 1.6s\n","                   all        130        668      0.892      0.915       0.93      0.669\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     86/120      4.13G      1.101      0.699      1.077         65        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.1it/s 15.5s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.7it/s 1.9s\n","                   all        130        668      0.915      0.902      0.932      0.673\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     87/120      4.13G      1.091     0.6865       1.09         85        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.2it/s 15.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.1it/s 2.4s\n","                   all        130        668      0.912        0.9      0.935      0.673\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     88/120      4.13G      1.091      0.688       1.08         60        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.1it/s 15.4s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.9it/s 1.8s\n","                   all        130        668      0.904      0.914      0.941      0.681\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     89/120      4.13G      1.107     0.6797      1.083        103        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.2it/s 15.1s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.0it/s 1.7s\n","                   all        130        668      0.907      0.917      0.935      0.671\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     90/120      4.13G      1.106     0.6968      1.099        146        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.2it/s 14.8s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.2it/s 2.3s\n","                   all        130        668       0.89      0.928       0.93      0.677\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     91/120      4.13G      1.115     0.6993      1.095        181        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.1it/s 15.5s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.8it/s 1.8s\n","                   all        130        668      0.912        0.9      0.927      0.674\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     92/120      4.13G      1.091      0.696       1.09         72        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.3it/s 14.1s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.8it/s 1.8s\n","                   all        130        668      0.908      0.905      0.928      0.669\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     93/120      4.35G      1.102     0.6812      1.087         79        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.2it/s 15.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.7it/s 1.8s\n","                   all        130        668      0.908      0.899      0.924      0.664\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     94/120      4.36G      1.073     0.6707      1.062        125        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.2it/s 14.7s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.3it/s 2.2s\n","                   all        130        668      0.888      0.901      0.926       0.67\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     95/120      4.38G      1.097     0.6889      1.085         78        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.1it/s 15.8s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.8it/s 1.8s\n","                   all        130        668       0.88      0.922      0.932      0.681\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     96/120      4.41G      1.096     0.6915      1.087         89        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.2it/s 15.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.0it/s 1.6s\n","                   all        130        668      0.891      0.912      0.934      0.675\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     97/120      4.43G        1.1     0.6691      1.073         94        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.2it/s 15.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.0it/s 2.4s\n","                   all        130        668      0.894      0.923      0.933      0.678\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     98/120      4.72G      1.092     0.6895      1.084        114        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.4it/s 13.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.8it/s 1.3s\n","                   all        130        668      0.891       0.92      0.935      0.681\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     99/120      4.74G      1.081     0.6688      1.089         68        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.2it/s 14.7s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.8it/s 1.8s\n","                   all        130        668      0.884      0.924      0.929      0.676\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K    100/120      4.77G        1.1     0.6736       1.07         86        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.3it/s 14.7s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.3it/s 2.2s\n","                   all        130        668      0.874      0.925      0.928      0.679\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K    101/120      4.79G      1.083     0.6712      1.097        228        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.2it/s 14.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.8it/s 1.8s\n","                   all        130        668      0.888      0.923      0.927      0.672\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K    102/120      4.82G      1.107     0.6725       1.08         69        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.2it/s 15.1s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.1it/s 1.6s\n","                   all        130        668      0.894      0.908      0.927      0.669\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K    103/120      4.84G      1.084     0.6765       1.08         77        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.2it/s 15.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.3it/s 2.2s\n","                   all        130        668      0.893       0.91      0.927      0.672\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K    104/120      4.87G      1.064     0.6731      1.071         46        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.1it/s 15.8s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.7it/s 1.9s\n","                   all        130        668      0.921      0.894      0.929      0.678\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K    105/120      4.89G       1.09     0.6787      1.093         89        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.2it/s 14.8s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.0it/s 1.7s\n","                   all        130        668      0.888      0.922      0.928       0.68\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K    106/120      4.91G      1.074     0.6696      1.073         79        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.2it/s 14.7s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.8it/s 1.8s\n","                   all        130        668      0.886      0.917      0.927      0.679\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K    107/120      4.94G      1.066     0.6507      1.072         92        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.3it/s 14.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.0it/s 2.5s\n","                   all        130        668      0.915      0.892      0.927      0.675\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K    108/120      4.96G      1.076     0.6582      1.076         63        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.1it/s 15.4s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.2it/s 1.5s\n","                   all        130        668      0.896      0.922      0.928      0.675\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K    109/120      4.98G      1.124     0.6984      1.105        105        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.2it/s 15.1s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.8it/s 1.8s\n","                   all        130        668      0.908      0.924      0.929      0.671\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K    110/120      5.01G      1.068     0.6693      1.078        113        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.3it/s 14.6s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.1it/s 2.4s\n","                   all        130        668      0.892      0.917      0.925      0.675\n","Closing dataloader mosaic\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K    111/120      5.04G      1.009     0.6352      1.064         35        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.1it/s 15.7s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.0it/s 1.6s\n","                   all        130        668      0.857      0.923      0.916      0.655\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K    112/120      5.06G       1.02     0.6282      1.049         59        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.4it/s 13.8s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.7it/s 1.9s\n","                   all        130        668      0.844      0.907      0.908       0.65\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K    113/120      5.08G      1.007     0.6124      1.055         26        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.6it/s 12.8s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.1it/s 1.6s\n","                   all        130        668      0.851      0.909      0.912      0.657\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K    114/120      5.11G      1.003     0.5806      1.049         36        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.5it/s 13.4s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.3it/s 2.2s\n","                   all        130        668       0.83      0.926      0.911      0.661\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K    115/120      5.13G     0.9657     0.5676      1.036         33        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.7it/s 12.4s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.2it/s 2.3s\n","                   all        130        668      0.834      0.932      0.916      0.664\n","\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 40 epochs. Best results observed at epoch 75, best model saved as best.pt.\n","To update EarlyStopping(patience=40) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n","\n","115 epochs completed in 0.581 hours.\n","Optimizer stripped from /content/drive/My Drive/YOLOv8_NWPU_VHR10/Training_Runs/NWPU_VHR10_yolov8s_balanced_materialized/weights/last.pt, 22.5MB\n","Optimizer stripped from /content/drive/My Drive/YOLOv8_NWPU_VHR10/Training_Runs/NWPU_VHR10_yolov8s_balanced_materialized/weights/best.pt, 22.5MB\n","\n","Validating /content/drive/My Drive/YOLOv8_NWPU_VHR10/Training_Runs/NWPU_VHR10_yolov8s_balanced_materialized/weights/best.pt...\n","Ultralytics 8.3.223 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n","Model summary (fused): 72 layers, 11,129,454 parameters, 0 gradients, 28.5 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 1.6it/s 3.1s\n","                   all        130        668      0.893       0.93      0.937      0.684\n","              airplane         16        118      0.978      0.992      0.988      0.717\n","                  ship          8         52       0.87      0.923      0.948      0.653\n","          storage tank          3         94      0.931          1      0.984       0.76\n","      baseball diamond         37         69      0.866      0.986      0.977      0.799\n","          tennis court         20        106      0.699      0.766      0.695       0.54\n","      basketball court         17         26      0.995          1      0.995      0.782\n","    ground track field         39         39      0.979          1      0.995      0.809\n","                harbor          9         67      0.871      0.866      0.909      0.619\n","                bridge         11         19      0.887      0.825      0.925      0.525\n","               vehicle         15         78      0.859      0.941      0.959      0.641\n","Speed: 0.2ms preprocess, 4.7ms inference, 0.0ms loss, 4.5ms postprocess per image\n","Results saved to \u001b[1m/content/drive/My Drive/YOLOv8_NWPU_VHR10/Training_Runs/NWPU_VHR10_yolov8s_balanced_materialized\u001b[0m\n","\n","Training finished.\n","Saved best model: /content/drive/My Drive/YOLOv8_NWPU_VHR10/Models/yolov8s_nwpu_vhr_10_best_balanced.pt\n"]}]},{"cell_type":"code","source":["# ==========================================================================\n","# CELL 8: EXTRACT AND SAVE TRAINING METRICS\n","# ==========================================================================\n","\"\"\"\n","Extract training metrics (loss, precision, recall, mAP) from the results\n","and save them as CSV files for analysis.\n","\"\"\"\n","\n","import pandas as pd\n","import json\n","from pathlib import Path\n","import shutil\n","\n","print(\"=\"*80)\n","print(\"EXTRACTING AND SAVING TRAINING METRICS\")\n","print(\"=\"*80)\n","\n","# Paths\n","runs_dir = Path('/content/drive/My Drive/YOLOv8_NWPU_VHR10/Training_Runs')\n","results_dir = Path('/content/drive/My Drive/YOLOv8_NWPU_VHR10/Results')\n","\n","# Find the latest run\n","run_dirs = sorted(runs_dir.glob('**/'), key=lambda x: x.stat().st_mtime, reverse=True)\n","latest_run = None\n","for run_dir in run_dirs:\n","    if (run_dir / 'weights').exists():\n","        latest_run = run_dir\n","        break\n","\n","if latest_run is None:\n","    print(\"‚úó No completed training runs found!\")\n","    print(\"  Please run CELL 7 first!\")\n","else:\n","    print(f\"‚úì Found latest run: {latest_run.name}\")\n","\n","    # Look for results.csv (YOLOv8 saves training metrics here)\n","    results_csv_path = latest_run / 'results.csv'\n","    if results_csv_path.exists():\n","        print(f\"\\n1. Loading training metrics from {results_csv_path.name}...\")\n","        # Load results CSV\n","        df_results = pd.read_csv(results_csv_path)\n","        # Clean column names (remove leading/trailing spaces)\n","        df_results.columns = df_results.columns.str.strip()\n","        print(f\"   ‚úì Loaded {len(df_results)} epochs of training data\")\n","        print(f\"   ‚úì Columns: {list(df_results.columns)}\")\n","\n","        # Display summary statistics\n","        print(f\"\\n2. Training Summary:\")\n","        print(f\"   Total Epochs: {len(df_results)}\")\n","\n","        # Try to extract key metrics\n","        metric_columns = {\n","            'train_loss': ['train/box_loss', 'box_loss'],\n","            'val_loss': ['val/box_loss', 'box_loss'],\n","            'precision': ['metrics/precision(B)', 'precision'],\n","            'recall': ['metrics/recall(B)', 'recall'],\n","            'mAP50': ['metrics/mAP50(B)', 'mAP50'],\n","            'mAP50_95': ['metrics/mAP50-95(B)', 'mAP50-95'],\n","        }\n","        for metric_name, possible_columns in metric_columns.items():\n","            for col in possible_columns:\n","                if col in df_results.columns:\n","                    last_value = df_results[col].iloc[-1]\n","                    print(f\"   ‚Ä¢ Final {metric_name}: {last_value:.6f}\")\n","                    break\n","\n","        # Save metrics to results directory\n","        print(f\"\\n3. Saving metrics to Results directory...\")\n","        # Save full results\n","        results_save_path = results_dir / 'nwpu_vhr10_training_metrics.csv'\n","        df_results.to_csv(results_save_path, index=False)\n","        print(f\"   ‚úì Saved: {results_save_path}\")\n","\n","        # Save summary statistics\n","        summary_dict = {}\n","        summary_dict['Total Epochs'] = len(df_results)\n","        for metric_name, possible_columns in metric_columns.items():\n","            for col in possible_columns:\n","                if col in df_results.columns:\n","                    summary_dict[f'Final {metric_name}'] = df_results[col].iloc[-1]\n","                    summary_dict[f'Best {metric_name}'] = df_results[col].max() if 'loss' not in metric_name else df_results[col].min()\n","                    summary_dict[f'Epoch of Best {metric_name}'] = int(df_results[col].idxmax()) if 'loss' not in metric_name else int(df_results[col].idxmin())\n","                    break\n","        summary_df = pd.DataFrame([summary_dict])\n","        summary_path = results_dir / 'nwpu_vhr10_training_summary.csv'\n","        summary_df.to_csv(summary_path, index=False)\n","        print(f\"   ‚úì Saved: {summary_path}\")\n","\n","        # Also save the validation results\n","        val_results_path = latest_run / 'weights' / 'best.pt'\n","        if val_results_path.exists():\n","            print(f\"\\n4. Model Information:\")\n","            print(f\"   ‚úì Best model: {val_results_path}\")\n","            print(f\"     Size: {val_results_path.stat().st_size / 1e6:.2f} MB\")\n","    else:\n","        print(f\"‚úó results.csv not found in {latest_run}\")\n","        print(f\"  Available files: {list(latest_run.glob('*.*'))}\")\n","\n","print(\"\\n‚úì Metrics extraction completed!\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B6WfxsJY7qoP","executionInfo":{"status":"ok","timestamp":1762005760627,"user_tz":-330,"elapsed":345,"user":{"displayName":"Manvi Sharma","userId":"13719445681117001639"}},"outputId":"0404045e-8d88-4ab2-ee8f-4b048a246990"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["================================================================================\n","EXTRACTING AND SAVING TRAINING METRICS\n","================================================================================\n","‚úì Found latest run: NWPU_VHR10_yolov8s_balanced_materialized\n","\n","1. Loading training metrics from results.csv...\n","   ‚úì Loaded 115 epochs of training data\n","   ‚úì Columns: ['epoch', 'time', 'train/box_loss', 'train/cls_loss', 'train/dfl_loss', 'metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)', 'val/box_loss', 'val/cls_loss', 'val/dfl_loss', 'lr/pg0', 'lr/pg1', 'lr/pg2']\n","\n","2. Training Summary:\n","   Total Epochs: 115\n","   ‚Ä¢ Final train_loss: 0.965690\n","   ‚Ä¢ Final val_loss: 1.060210\n","   ‚Ä¢ Final precision: 0.834240\n","   ‚Ä¢ Final recall: 0.932340\n","   ‚Ä¢ Final mAP50: 0.915510\n","   ‚Ä¢ Final mAP50_95: 0.663830\n","\n","3. Saving metrics to Results directory...\n","   ‚úì Saved: /content/drive/My Drive/YOLOv8_NWPU_VHR10/Results/nwpu_vhr10_training_metrics.csv\n","   ‚úì Saved: /content/drive/My Drive/YOLOv8_NWPU_VHR10/Results/nwpu_vhr10_training_summary.csv\n","\n","4. Model Information:\n","   ‚úì Best model: /content/drive/My Drive/YOLOv8_NWPU_VHR10/Training_Runs/NWPU_VHR10_yolov8s_balanced_materialized/weights/best.pt\n","     Size: 22.53 MB\n","\n","‚úì Metrics extraction completed!\n"]}]},{"cell_type":"code","source":["# ==========================================================================\n","# CELL 9: VALIDATE MODEL ON VALIDATION SET & CALCULATE PER-CLASS METRICS\n","# ==========================================================================\n","\"\"\"\n","Validate the trained model on the validation set and extract per-class\n","metrics for analysis and comparison.\n","\"\"\"\n","\n","from ultralytics import YOLO\n","import pandas as pd\n","from pathlib import Path\n","import json\n","\n","print(\"=\"*80)\n","print(\"VALIDATING MODEL ON VALIDATION SET\")\n","print(\"=\"*80)\n","\n","# Paths\n","models_dir = Path('/content/drive/My Drive/YOLOv8_NWPU_VHR10/Models')\n","dataset_processed_dir = Path('/content/drive/My Drive/YOLOv8_NWPU_VHR10/NWPU_VHR-10_YOLO_Format')\n","results_dir = Path('/content/drive/My Drive/YOLOv8_NWPU_VHR10/Results')\n","yaml_path = dataset_processed_dir / 'dataset.yaml'\n","\n","# Best model path\n","best_model_path = models_dir / 'yolov8s_nwpu_vhr_10_best_balanced.pt'\n","if not best_model_path.exists():\n","    print(f\"‚úó Best model not found at {best_model_path}\")\n","    print(\"  Please run CELL 7 first!\")\n","else:\n","    print(f\"‚úì Loading best model: {best_model_path.name}\")\n","\n","    # Load trained model\n","    model = YOLO(str(best_model_path))\n","\n","    print(\"\\n1. Running validation...\")\n","    # Validate model\n","    val_results = model.val(\n","        data=str(yaml_path),\n","        split='val',\n","        imgsz=640,\n","        batch=16,\n","        verbose=True,\n","        save_json=True,  # Save results as JSON\n","    )\n","\n","    print(\"\\n2. Validation completed!\")\n","\n","    # Extract overall metrics\n","    print(f\"\\n3. Overall Metrics:\")\n","    print(f\"   mAP@50: {val_results.box.map50:.4f}\")\n","    print(f\"   mAP@50:95: {val_results.box.map:.4f}\")\n","    print(f\"   Precision: {val_results.box.mp:.4f}\")\n","    print(f\"   Recall: {val_results.box.mr:.4f}\")\n","\n","    # Create overall metrics DataFrame\n","    overall_metrics = {\n","        'Model': 'YOLOv8 Small (NWPU VHR-10)',\n","        'mAP@50': val_results.box.map50,\n","        'mAP@50:95': val_results.box.map,\n","        'Precision': val_results.box.mp,\n","        'Recall': val_results.box.mr,\n","        'F1_Score': 2 * (val_results.box.mp * val_results.box.mr) / (val_results.box.mp + val_results.box.mr + 1e-9),\n","    }\n","    overall_df = pd.DataFrame([overall_metrics])\n","    overall_metrics_path = results_dir / 'nwpu_vhr10_overall_metrics.csv'\n","    overall_df.to_csv(overall_metrics_path, index=False)\n","    print(f\"\\n   ‚úì Saved: {overall_metrics_path}\")\n","\n","    # Extract per-class metrics (if available)\n","    print(f\"\\n4. Per-Class Metrics:\")\n","    class_names = [\n","        'airplane', 'ship', 'storage tank', 'baseball diamond', 'tennis court',\n","        'basketball court', 'ground track field', 'harbor', 'bridge', 'vehicle'\n","    ]\n","\n","    # YOLOv8 provides class-wise statistics\n","    if hasattr(val_results.box, 'maps'):\n","        per_class_data = []\n","        for class_id, class_name in enumerate(class_names):\n","            if class_id < len(val_results.box.maps):\n","                map_value = val_results.box.maps[class_id]\n","                per_class_data.append({\n","                    'Class': class_name,\n","                    'Class_ID': class_id,\n","                    'AP@50': map_value,\n","                })\n","                print(f\"   {class_name:20s}: AP@50 = {map_value:.4f}\")\n","        if per_class_data:\n","            per_class_df = pd.DataFrame(per_class_data)\n","            per_class_metrics_path = results_dir / 'nwpu_vhr10_per_class_metrics.csv'\n","            per_class_df.to_csv(per_class_metrics_path, index=False)\n","            print(f\"\\n   ‚úì Saved: {per_class_metrics_path}\")\n","\n","print(\"\\n‚úì Validation completed successfully!\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zAVLlooI7zUZ","executionInfo":{"status":"ok","timestamp":1762005769106,"user_tz":-330,"elapsed":8451,"user":{"displayName":"Manvi Sharma","userId":"13719445681117001639"}},"outputId":"54336d0b-1692-4e1d-e770-812c6af8c4c8"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["================================================================================\n","VALIDATING MODEL ON VALIDATION SET\n","================================================================================\n","‚úì Loading best model: yolov8s_nwpu_vhr_10_best_balanced.pt\n","\n","1. Running validation...\n","Ultralytics 8.3.223 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n","Model summary (fused): 72 layers, 11,129,454 parameters, 0 gradients, 28.5 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.3¬±0.1 ms, read: 64.6¬±32.7 MB/s, size: 94.8 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/My Drive/YOLOv8_NWPU_VHR10/NWPU_VHR-10_YOLO_Format/labels/val.cache... 130 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 130/130 74.9Kit/s 0.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 2.2it/s 4.1s\n","                   all        130        668      0.893      0.927      0.936      0.681\n","              airplane         16        118      0.978      0.992      0.988      0.711\n","                  ship          8         52      0.889      0.923       0.95      0.651\n","          storage tank          3         94      0.934          1      0.981      0.759\n","      baseball diamond         37         69      0.867      0.986      0.972      0.786\n","          tennis court         20        106      0.696      0.764      0.694      0.538\n","      basketball court         17         26          1       0.99      0.995      0.781\n","    ground track field         39         39       0.98          1      0.995      0.806\n","                harbor          9         67      0.893      0.871      0.916      0.618\n","                bridge         11         19      0.834      0.796      0.906      0.521\n","               vehicle         15         78       0.86      0.948      0.962      0.638\n","Speed: 3.3ms preprocess, 10.3ms inference, 0.0ms loss, 2.8ms postprocess per image\n","Saving /content/runs/detect/val/predictions.json...\n","Results saved to \u001b[1m/content/runs/detect/val\u001b[0m\n","\n","2. Validation completed!\n","\n","3. Overall Metrics:\n","   mAP@50: 0.9360\n","   mAP@50:95: 0.6808\n","   Precision: 0.8932\n","   Recall: 0.9269\n","\n","   ‚úì Saved: /content/drive/My Drive/YOLOv8_NWPU_VHR10/Results/nwpu_vhr10_overall_metrics.csv\n","\n","4. Per-Class Metrics:\n","   airplane            : AP@50 = 0.7110\n","   ship                : AP@50 = 0.6513\n","   storage tank        : AP@50 = 0.7591\n","   baseball diamond    : AP@50 = 0.7858\n","   tennis court        : AP@50 = 0.5379\n","   basketball court    : AP@50 = 0.7808\n","   ground track field  : AP@50 = 0.8057\n","   harbor              : AP@50 = 0.6180\n","   bridge              : AP@50 = 0.5207\n","   vehicle             : AP@50 = 0.6375\n","\n","   ‚úì Saved: /content/drive/My Drive/YOLOv8_NWPU_VHR10/Results/nwpu_vhr10_per_class_metrics.csv\n","\n","‚úì Validation completed successfully!\n"]}]}]}