{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1vjsEw58Sgu-qdTG6D9ly1Q2yznZCUNSY","timestamp":1762007483339}],"gpuType":"T4","authorship_tag":"ABX9TyMnxyjW+ybzipzYDcC6TE8J"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["# ==========================================================================\n","# CELL 1: INSTALL LIBRARIES AND MOUNT GOOGLE DRIVE\n","# ==========================================================================\n","\"\"\"\n","This cell installs all required libraries for:\n","- YOLOv8 training and inference\n","- COCO dataset handling\n","- Data preprocessing\n","- GPU acceleration\n","\"\"\"\n","# Install ultralytics (YOLOv5)\n","!pip install -q ultralytics\n","# Install additional required libraries\n","!pip install -q opencv-python pillow numpy pandas matplotlib seaborn\n","!pip install -q torch torchvision torchaudio  # PyTorch (should be pre-installed on Colab, but ensured here)\n","!pip install -q tqdm requests  # For downloading and progress tracking\n","!pip install -q scikit-learn  # For metrics calculation\n","\n","# Mount Google Drive to save dataset and models\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","print(\"‚úì All libraries installed successfully!\")\n","print(\"‚úì Google Drive mounted successfully!\")\n","\n","# Verify GPU availability\n","import torch\n","print(f\"\\n‚úì GPU Available: {torch.cuda.is_available()}\")\n","if torch.cuda.is_available():\n","    print(f\"  GPU Name: {torch.cuda.get_device_name(0)}\")\n","    print(f\"  GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"80LxYAA67W7m","executionInfo":{"status":"ok","timestamp":1762011437331,"user_tz":-330,"elapsed":31537,"user":{"displayName":"Manvi Sharma","userId":"13719445681117001639"}},"outputId":"8415a546-a77c-43c9-dc99-737a20db23e9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","‚úì All libraries installed successfully!\n","‚úì Google Drive mounted successfully!\n","\n","‚úì GPU Available: True\n","  GPU Name: Tesla T4\n","  GPU Memory: 15.83 GB\n"]}]},{"cell_type":"code","source":["# ==========================================================================\n","# CELL 2: CREATE DIRECTORY STRUCTURE IN GOOGLE DRIVE\n","# ==========================================================================\n","\"\"\"\n","Create organized folder structure in Google Drive to store:\n","1. Raw NWPU VHR-10 dataset\n","2. Processed dataset in YOLO format\n","3. Trained models and checkpoints\n","4. Training logs and results\n","\"\"\"\n","\n","import os\n","from pathlib import Path\n","\n","# Define base directories in Google Drive\n","base_drive = '/content/drive/My Drive'\n","\n","# Create main project directory\n","project_dir = Path(base_drive) / 'YOLO_NWPU_VHR10'\n","project_dir.mkdir(exist_ok=True)\n","\n","# Create subdirectories\n","dataset_raw_dir = project_dir / 'NWPU_VHR-10'  # Store raw downloaded dataset\n","dataset_processed_dir = project_dir / 'NWPU_VHR-10_YOLO_Format'  # Store processed YOLO dataset\n","models_dir = project_dir / 'Models'  # Store trained models\n","results_dir = project_dir / 'Results/YOLOv5'  # Store metrics and results\n","runs_dir = project_dir / 'Training_Runs'  # Store training logs\n","\n","# Create all directories\n","for directory in [dataset_raw_dir, dataset_processed_dir, models_dir, results_dir, runs_dir]:\n","    directory.mkdir(parents=True, exist_ok=True)\n","    print(f\"‚úì Created: {directory}\")\n","\n","# Display directory structure\n","print(\"\\n\" + \"=\"*80)\n","print(\"DIRECTORY STRUCTURE CREATED:\")\n","print(\"=\"*80)\n","print(f\"\"\"\n","{project_dir}/\n","‚îú‚îÄ‚îÄ NWPU_VHR-10/                    (Raw dataset - will be downloaded here)\n","‚îú‚îÄ‚îÄ NWPU_VHR-10_YOLO_Format/        (Processed dataset in YOLO format)\n","‚îú‚îÄ‚îÄ Models/                         (Trained model weights)\n","‚îú‚îÄ‚îÄ Results/YOLOv5                        (Metrics and analysis results)\n","‚îî‚îÄ‚îÄ Training_Runs/                  (Training logs and checkpoints)\n","\"\"\")\n","\n","# Define paths as variables for easy reference\n","print(f\"\\nKey Paths:\")\n","print(f\"  Raw Dataset: {dataset_raw_dir}\")\n","print(f\"  YOLO Dataset: {dataset_processed_dir}\")\n","print(f\"  Models: {models_dir}\")\n","print(f\"  Results: {results_dir}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qFMe_Okf7YVB","executionInfo":{"status":"ok","timestamp":1762011437355,"user_tz":-330,"elapsed":13,"user":{"displayName":"Manvi Sharma","userId":"13719445681117001639"}},"outputId":"e36346e6-f635-4dd5-90e8-c2e38ced8204"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úì Created: /content/drive/My Drive/YOLO_NWPU_VHR10/NWPU_VHR-10\n","‚úì Created: /content/drive/My Drive/YOLO_NWPU_VHR10/NWPU_VHR-10_YOLO_Format\n","‚úì Created: /content/drive/My Drive/YOLO_NWPU_VHR10/Models\n","‚úì Created: /content/drive/My Drive/YOLO_NWPU_VHR10/Results/YOLOv5\n","‚úì Created: /content/drive/My Drive/YOLO_NWPU_VHR10/Training_Runs\n","\n","================================================================================\n","DIRECTORY STRUCTURE CREATED:\n","================================================================================\n","\n","/content/drive/My Drive/YOLO_NWPU_VHR10/\n","‚îú‚îÄ‚îÄ NWPU_VHR-10/                    (Raw dataset - will be downloaded here)\n","‚îú‚îÄ‚îÄ NWPU_VHR-10_YOLO_Format/        (Processed dataset in YOLO format)\n","‚îú‚îÄ‚îÄ Models/                         (Trained model weights)\n","‚îú‚îÄ‚îÄ Results/YOLOv5                        (Metrics and analysis results)\n","‚îî‚îÄ‚îÄ Training_Runs/                  (Training logs and checkpoints)\n","\n","\n","Key Paths:\n","  Raw Dataset: /content/drive/My Drive/YOLO_NWPU_VHR10/NWPU_VHR-10\n","  YOLO Dataset: /content/drive/My Drive/YOLO_NWPU_VHR10/NWPU_VHR-10_YOLO_Format\n","  Models: /content/drive/My Drive/YOLO_NWPU_VHR10/Models\n","  Results: /content/drive/My Drive/YOLO_NWPU_VHR10/Results/YOLOv5\n"]}]},{"cell_type":"code","source":["# ==========================================================================\n","# CELL 3: DOWNLOAD NWPU VHR-10 DATASET\n","# ==========================================================================\n","\"\"\"\n","Download NWPU VHR-10 dataset from official sources (torchgeo)\n","Dataset Info:\n","- Total: 800 images\n","- Positive set: 650 images (contain objects)\n","- Negative set: 150 images (no objects)\n","- Classes: 10 (airplane, ship, storage tank, baseball diamond, tennis court,\n","           basketball court, ground track field, harbor, bridge, vehicle)\n","- Resolution: 0.5-2m (Google Earth), 0.08m (Vaihingen)\n","\"\"\"\n","\n","import zipfile\n","import requests\n","from tqdm import tqdm\n","import shutil\n","\n","# Path where dataset will be downloaded\n","from pathlib import Path\n","dataset_raw_dir = Path(dataset_raw_dir)\n","\n","print(\"=\"*80)\n","print(\"DOWNLOADING NWPU VHR-10 DATASET\")\n","print(\"=\"*80)\n","\n","# Download from torchgeo (official source)\n","# Note: If this link doesn't work, alternative: download from\n","# Google Cloud, Baidu Pan, or other mirrors\n","dataset_url = 'https://hf.co/datasets/torchgeo/vhr10/resolve/main/NWPU%20VHR-10%20dataset.zip'\n","annotations_url = 'https://hf.co/datasets/torchgeo/vhr10/resolve/main/annotations.json'\n","\n","# Download dataset zip file\n","dataset_zip_path = dataset_raw_dir / 'NWPU_VHR-10_dataset.zip'\n","print(f\"\\n1. Downloading dataset images (this may take 5-10 minutes)...\")\n","print(f\"   URL: {dataset_url}\")\n","print(f\"   Saving to: {dataset_zip_path}\")\n","try:\n","    # Download with progress bar\n","    response = requests.get(dataset_url, stream=True)\n","    total_size = int(response.headers.get('content-length', 0))\n","    with open(dataset_zip_path, 'wb') as f:\n","        with tqdm(total=total_size, unit='B', unit_scale=True, desc='Downloading dataset') as pbar:\n","            for chunk in response.iter_content(chunk_size=8192):\n","                f.write(chunk)\n","                pbar.update(len(chunk))\n","    print(\"‚úì Dataset download completed!\")\n","except Exception as e:\n","    print(f\"‚úó Error downloading dataset: {e}\")\n","    print(\"\\nAlternative: Download manually from:\")\n","    print(\"  - https://hf.co/datasets/torchgeo/vhr10\")\n","    print(\"  - Google Cloud Storage\")\n","    print(\"  - Baidu Pan (search NWPU VHR-10)\")\n","\n","# Download annotations JSON\n","annotations_path = dataset_raw_dir / 'annotations.json'\n","print(f\"\\n2. Downloading annotations file...\")\n","print(f\"   URL: {annotations_url}\")\n","print(f\"   Saving to: {annotations_path}\")\n","try:\n","    response = requests.get(annotations_url, stream=True)\n","    total_size = int(response.headers.get('content-length', 0))\n","    with open(annotations_path, 'wb') as f:\n","        with tqdm(total=total_size, unit='B', unit_scale=True, desc='Downloading annotations') as pbar:\n","            for chunk in response.iter_content(chunk_size=8192):\n","                f.write(chunk)\n","                pbar.update(len(chunk))\n","    print(\"‚úì Annotations download completed!\")\n","except Exception as e:\n","    print(f\"‚úó Error downloading annotations: {e}\")\n","\n","# Extract zip file\n","print(f\"\\n3. Extracting dataset (this may take 2-3 minutes)...\")\n","print(f\"   Extracting to: {dataset_raw_dir}\")\n","try:\n","    with zipfile.ZipFile(dataset_zip_path, 'r') as zip_ref:\n","        zip_ref.extractall(dataset_raw_dir)\n","    # Remove zip file to save space\n","    import os\n","    os.remove(dataset_zip_path)\n","    print(\"‚úì Dataset extraction completed!\")\n","except Exception as e:\n","    print(f\"‚úó Error extracting dataset: {e}\")\n","\n","# Verify downloaded files\n","print(f\"\\n4. Verifying downloaded files...\")\n","if annotations_path.exists():\n","    print(f\"   ‚úì Annotations: {annotations_path} ({annotations_path.stat().st_size / 1e6:.2f} MB)\")\n","\n","# List directory contents\n","print(f\"\\n5. Dataset directory contents:\")\n","for item in dataset_raw_dir.iterdir():\n","    if item.is_dir():\n","        file_count = len(list(item.glob('*')))\n","        print(f\"   üìÅ {item.name}/ ({file_count} items)\")\n","    else:\n","        print(f\"   üìÑ {item.name} ({item.stat().st_size / 1e6:.2f} MB)\")\n","\n","print(\"\\n‚úì Download and extraction completed!\")\n"],"metadata":{"id":"Xye-5Nxw7YRj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1762011457554,"user_tz":-330,"elapsed":20185,"user":{"displayName":"Manvi Sharma","userId":"13719445681117001639"}},"outputId":"dcd76262-56a8-45c9-f2c5-da11fb106f57"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["================================================================================\n","DOWNLOADING NWPU VHR-10 DATASET\n","================================================================================\n","\n","1. Downloading dataset images (this may take 5-10 minutes)...\n","   URL: https://hf.co/datasets/torchgeo/vhr10/resolve/main/NWPU%20VHR-10%20dataset.zip\n","   Saving to: /content/drive/My Drive/YOLO_NWPU_VHR10/NWPU_VHR-10/NWPU_VHR-10_dataset.zip\n"]},{"output_type":"stream","name":"stderr","text":["Downloading dataset: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 76.8M/76.8M [00:00<00:00, 110MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["‚úì Dataset download completed!\n","\n","2. Downloading annotations file...\n","   URL: https://hf.co/datasets/torchgeo/vhr10/resolve/main/annotations.json\n","   Saving to: /content/drive/My Drive/YOLO_NWPU_VHR10/NWPU_VHR-10/annotations.json\n"]},{"output_type":"stream","name":"stderr","text":["Downloading annotations: 1.27MB [00:00, 20.3MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["‚úì Annotations download completed!\n","\n","3. Extracting dataset (this may take 2-3 minutes)...\n","   Extracting to: /content/drive/My Drive/YOLO_NWPU_VHR10/NWPU_VHR-10\n","‚úì Dataset extraction completed!\n","\n","4. Verifying downloaded files...\n","   ‚úì Annotations: /content/drive/My Drive/YOLO_NWPU_VHR10/NWPU_VHR-10/annotations.json (1.27 MB)\n","\n","5. Dataset directory contents:\n","   üìÑ annotations.json (1.27 MB)\n","   üìÅ NWPU VHR-10 dataset/ (4 items)\n","\n","‚úì Download and extraction completed!\n"]}]},{"cell_type":"code","source":["# ==========================================================================\n","# CELL 4: CONVERT COCO FORMAT TO YOLO FORMAT (CORRECTED)\n","# ==========================================================================\n","\"\"\"\n","Convert downloaded dataset from COCO format (JSON annotations) to YOLO format\n","(text files with normalized bounding box coordinates).\n","COCO Format: {\"image_id\", \"bbox\": [x_min, y_min, width, height], \"category_id\"}\n","YOLO Format: <class_id> <x_center_norm> <y_center_norm> <width_norm> <height_norm> (normalized to 0-1)\n","\"\"\"\n","\n","import json\n","import os\n","from pathlib import Path\n","from PIL import Image\n","import numpy as np\n","import shutil  # FIX 1: Missing import!\n","\n","print(\"=\"*80)\n","print(\"CONVERTING COCO FORMAT TO YOLO FORMAT\")\n","print(\"=\"*80)\n","\n","# Paths\n","dataset_raw_dir = Path('/content/drive/My Drive/YOLO_NWPU_VHR10/NWPU_VHR-10')\n","dataset_processed_dir = Path('/content/drive/My Drive/YOLO_NWPU_VHR10/NWPU_VHR-10_YOLO_Format')\n","annotations_path = dataset_raw_dir / 'annotations.json'\n","\n","# Class mapping for NWPU VHR-10\n","# COCO format uses category_id (1-indexed)\n","class_mapping = {\n","    0: 'background',\n","    1: 'airplane',\n","    2: 'ship',\n","    3: 'storage tank',\n","    4: 'baseball diamond',\n","    5: 'tennis court',\n","    6: 'basketball court',\n","    7: 'ground track field',\n","    8: 'harbor',\n","    9: 'bridge',\n","    10: 'vehicle'\n","}\n","\n","# Load COCO annotations\n","print(\"\\n1. Loading COCO annotations...\")\n","with open(annotations_path, 'r') as f:\n","    coco_data = json.load(f)\n","print(f\"   ‚úì Loaded {len(coco_data['images'])} images\")\n","print(f\"   ‚úì Loaded {len(coco_data['annotations'])} annotations\")\n","\n","# Create category mapping (COCO ID -> class index for YOLO)\n","coco_categories = {cat['id']: idx for idx, cat in enumerate(coco_data['categories'])}\n","\n","# Create image ID to annotations mapping\n","image_annotations = {}\n","for ann in coco_data['annotations']:\n","    img_id = ann['image_id']\n","    if img_id not in image_annotations:\n","        image_annotations[img_id] = []\n","    image_annotations[img_id].append(ann)\n","\n","# FIX 2: Since you have \"NWPU VHR-10 dataset\" -> \"positive image set\"\n","# Look for this nested structure\n","print(\"\\n2. Finding positive images directory...\")\n","positive_images_dir = None\n","\n","# First try: Look for nested structure\n","nested_path = dataset_raw_dir / 'NWPU VHR-10 dataset' / 'positive image set'\n","if nested_path.exists():\n","    positive_images_dir = nested_path\n","    print(f\"   ‚úì Found positive images at: {positive_images_dir}\")\n","else:\n","    # Fallback: Search for any directory with 'positive' in name\n","    for item in dataset_raw_dir.rglob('*'):\n","        if item.is_dir() and 'positive' in item.name.lower():\n","            positive_images_dir = item\n","            print(f\"   ‚úì Found positive images at: {positive_images_dir}\")\n","            break\n","\n","if positive_images_dir is None:\n","    print(\"‚úó Could not find 'positive image set' directory\")\n","    print(\"  Available directories:\")\n","    for item in dataset_raw_dir.rglob('*'):\n","        if item.is_dir():\n","            print(f\"    - {item}\")\n","    raise Exception(\"Cannot find positive image set directory!\")\n","\n","# Convert annotations\n","print(\"\\n3. Converting annotations to YOLO format...\")\n","\n","# Create images and labels directories in YOLO format directory\n","images_dir = dataset_processed_dir / 'images'\n","labels_dir = dataset_processed_dir / 'labels'\n","images_dir.mkdir(parents=True, exist_ok=True)  # FIX 3: Added parents=True\n","labels_dir.mkdir(parents=True, exist_ok=True)\n","\n","conversion_count = 0\n","error_count = 0\n","\n","for coco_image in coco_data['images']:\n","    try:\n","        img_id = coco_image['id']\n","        img_file_name = coco_image['file_name']\n","        # FIX 4: Handle missing width/height in COCO JSON\n","        img_width = coco_image.get('width')\n","        img_height = coco_image.get('height')\n","\n","        # Find source image\n","        source_img_path = positive_images_dir / img_file_name\n","        if not source_img_path.exists():\n","            # Try with just filename (no path)\n","            if '/' in img_file_name:\n","                img_file_name = img_file_name.split('/')[-1]\n","                source_img_path = positive_images_dir / img_file_name\n","\n","        if not source_img_path.exists():\n","            print(f\"   ‚úó Image not found: {img_file_name}\")\n","            error_count += 1\n","            continue\n","\n","        # FIX 5: If dimensions missing, read from actual image\n","        if img_width is None or img_height is None:\n","            with Image.open(source_img_path) as img:\n","                img_width, img_height = img.size\n","\n","        # Copy image to processed directory\n","        dest_img_path = images_dir / img_file_name\n","        shutil.copy2(source_img_path, dest_img_path)\n","\n","        # Create YOLO format annotation\n","        yolo_annotations = []\n","        if img_id in image_annotations:\n","            for ann in image_annotations[img_id]:\n","                # Extract COCO bbox (x_min, y_min, width, height)\n","                x_min, y_min, bbox_width, bbox_height = ann['bbox']\n","                # Convert to center coordinates\n","                x_center = x_min + bbox_width / 2\n","                y_center = y_min + bbox_height / 2\n","                # Normalize to 0-1\n","                x_center_norm = x_center / img_width\n","                y_center_norm = y_center / img_height\n","                width_norm = bbox_width / img_width\n","                height_norm = bbox_height / img_height\n","                # Get YOLO class ID (0-indexed, excluding background)\n","                coco_category_id = ann['category_id']\n","                yolo_class_id = coco_categories[coco_category_id]\n","                yolo_annotations.append(f\"{yolo_class_id} {x_center_norm:.6f} {y_center_norm:.6f} {width_norm:.6f} {height_norm:.6f}\")\n","\n","        # FIX 6: Use Path.stem to get filename without extension\n","        label_file_name = Path(img_file_name).stem + '.txt'\n","        label_path = labels_dir / label_file_name\n","        with open(label_path, 'w') as f:\n","            f.write('\\n'.join(yolo_annotations))\n","\n","        conversion_count += 1\n","        if conversion_count % 100 == 0:\n","            print(f\"   ‚úì Converted {conversion_count} images...\")\n","    except Exception as e:\n","        print(f\"   ‚úó Error processing image {coco_image.get('file_name', 'unknown')}: {e}\")\n","        error_count += 1\n","\n","print(f\"\\n4. Conversion Summary:\")\n","print(f\"   ‚úì Successfully converted: {conversion_count} images\")\n","print(f\"   ‚úó Errors: {error_count}\")\n","\n","# Verify conversion\n","print(f\"\\n5. Verifying conversion...\")\n","image_files = list(images_dir.glob('*.jpg'))\n","label_files = list(labels_dir.glob('*.txt'))\n","print(f\"   ‚úì Images: {len(image_files)}\")\n","print(f\"   ‚úì Labels: {len(label_files)}\")\n","\n","# Check for mismatches\n","if len(image_files) != len(label_files):\n","    print(f\"   ‚ö† Warning: Mismatch between images ({len(image_files)}) and labels ({len(label_files)})\")\n","\n","# Display sample annotation\n","if label_files:\n","    sample_label = label_files[0]  # FIX 7: Get first label file, not list\n","    print(f\"\\n6. Sample YOLO annotation (from {sample_label.name}):\")\n","    with open(sample_label, 'r') as f:\n","        content = f.read()\n","        if content:\n","            # Show only first 3 lines\n","            lines = content.split('\\n')[:3]\n","            for line in lines:\n","                print(f\"   {line}\")\n","            if len(content.split('\\n')) > 3:\n","                print(f\"   ... ({len(content.split('\\n'))} total annotations)\")\n","        else:\n","            print(f\"   (empty - no objects)\")\n","\n","print(\"\\n\" + \"=\"*80)\n","print(\"‚úì DATASET SUCCESSFULLY CONVERTED TO YOLO FORMAT!\")\n","print(\"=\"*80)\n"],"metadata":{"id":"GIedA7Eq7YPM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1762011475738,"user_tz":-330,"elapsed":18170,"user":{"displayName":"Manvi Sharma","userId":"13719445681117001639"}},"outputId":"32808d07-fc16-42f1-f176-f4de143c23c8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["================================================================================\n","CONVERTING COCO FORMAT TO YOLO FORMAT\n","================================================================================\n","\n","1. Loading COCO annotations...\n","   ‚úì Loaded 650 images\n","   ‚úì Loaded 3921 annotations\n","\n","2. Finding positive images directory...\n","   ‚úì Found positive images at: /content/drive/My Drive/YOLO_NWPU_VHR10/NWPU_VHR-10/NWPU VHR-10 dataset/positive image set\n","\n","3. Converting annotations to YOLO format...\n","   ‚úì Converted 100 images...\n","   ‚úì Converted 200 images...\n","   ‚úì Converted 300 images...\n","   ‚úì Converted 400 images...\n","   ‚úì Converted 500 images...\n","   ‚úì Converted 600 images...\n","\n","4. Conversion Summary:\n","   ‚úì Successfully converted: 650 images\n","   ‚úó Errors: 0\n","\n","5. Verifying conversion...\n","   ‚úì Images: 650\n","   ‚úì Labels: 650\n","\n","6. Sample YOLO annotation (from 001.txt):\n","   0 0.622129 0.653465 0.068894 0.106436\n","\n","================================================================================\n","‚úì DATASET SUCCESSFULLY CONVERTED TO YOLO FORMAT!\n","================================================================================\n"]}]},{"cell_type":"code","source":["# ==========================================================================\n","# CELL 5: CREATE TRAIN/VAL SPLIT AND GENERATE dataset.yaml (FIXED)\n","# ==========================================================================\n","\"\"\"\n","Split the dataset into training (80%) and validation (20%) sets,\n","and create the dataset.yaml configuration file required by YOLOv8.\n","CRITICAL: YOLOv8 expects this structure:\n","  dataset/\n","    images/\n","      train/\n","      val/\n","    labels/\n","      train/\n","      val/\n","\"\"\"\n","\n","import os\n","import shutil\n","from pathlib import Path\n","import random\n","import yaml\n","\n","print(\"=\"*80)\n","print(\"CREATING TRAIN/VAL SPLIT\")\n","print(\"=\"*80)\n","\n","# Paths\n","dataset_processed_dir = Path('/content/drive/My Drive/YOLO_NWPU_VHR10/NWPU_VHR-10_YOLO_Format')\n","images_dir = dataset_processed_dir / 'images'\n","labels_dir = dataset_processed_dir / 'labels'\n","\n","# FIX: Create correct YOLO directory structure\n","# YOLOv8 expects: dataset/images/train and dataset/labels/train (parallel structure)\n","train_images_dir = dataset_processed_dir / 'images' / 'train'\n","train_labels_dir = dataset_processed_dir / 'labels' / 'train'\n","val_images_dir = dataset_processed_dir / 'images' / 'val'\n","val_labels_dir = dataset_processed_dir / 'labels' / 'val'\n","for directory in [train_images_dir, train_labels_dir, val_images_dir, val_labels_dir]:\n","    directory.mkdir(parents=True, exist_ok=True)\n","\n","# Get all image files from the converted dataset\n","all_images = sorted(list(images_dir.glob('*.jpg')))\n","print(f\"\\nTotal images: {len(all_images)}\")\n","if len(all_images) == 0:\n","    print(\"‚úó ERROR: No images found in converted dataset!\")\n","    print(f\"  Looking in: {images_dir}\")\n","    print(\"  Please check CELL 4 conversion completed successfully\")\n","    raise Exception(\"No images found for train/val split\")\n","\n","# Split into train (80%) and val (20%)\n","random.seed(42)  # For reproducibility\n","random.shuffle(all_images)\n","split_idx = int(0.8 * len(all_images))\n","train_images = all_images[:split_idx]\n","val_images = all_images[split_idx:]\n","\n","print(f\"Training images: {len(train_images)} (80%)\")\n","print(f\"Validation images: {len(val_images)} (20%)\")\n","\n","# Copy train images and labels\n","print(\"\\n1. Copying training images and labels...\")\n","train_copied = 0\n","train_errors = 0\n","for img_path in train_images:\n","    try:\n","        # Copy image\n","        shutil.copy2(img_path, train_images_dir / img_path.name)\n","        # Copy corresponding label\n","        label_path = labels_dir / f\"{img_path.stem}.txt\"\n","        if label_path.exists():\n","            shutil.copy2(label_path, train_labels_dir / label_path.name)\n","            train_copied += 1\n","        else:\n","            print(f\"   ‚ö† Label not found for: {img_path.name}\")\n","    except Exception as e:\n","        print(f\"   ‚úó Error copying {img_path.name}: {e}\")\n","        train_errors += 1\n","\n","print(f\"   ‚úì Copied {train_copied} training image-label pairs\")\n","if train_errors > 0:\n","    print(f\"   ‚úó Errors: {train_errors}\")\n","\n","# Copy val images and labels\n","print(\"\\n2. Copying validation images and labels...\")\n","val_copied = 0\n","val_errors = 0\n","for img_path in val_images:\n","    try:\n","        # Copy image\n","        shutil.copy2(img_path, val_images_dir / img_path.name)\n","        # Copy corresponding label\n","        label_path = labels_dir / f\"{img_path.stem}.txt\"\n","        if label_path.exists():\n","            shutil.copy2(label_path, val_labels_dir / label_path.name)\n","            val_copied += 1\n","        else:\n","            print(f\"   ‚ö† Label not found for: {img_path.name}\")\n","    except Exception as e:\n","        print(f\"   ‚úó Error copying {img_path.name}: {e}\")\n","        val_errors += 1\n","\n","print(f\"   ‚úì Copied {val_copied} validation image-label pairs\")\n","if val_errors > 0:\n","    print(f\"   ‚úó Errors: {val_errors}\")\n","\n","# Define class names for NWPU VHR-10 (10 classes, 0-indexed)\n","class_names = [\n","    'airplane',\n","    'ship',\n","    'storage tank',\n","    'baseball diamond',\n","    'tennis court',\n","    'basketball court',\n","    'ground track field',\n","    'harbor',\n","    'bridge',\n","    'vehicle'\n","]\n","\n","# FIX: Create dataset.yaml with CORRECT paths for YOLOv8\n","# YOLOv8 expects paths relative to the dataset root\n","# Structure: dataset_root/images/train and dataset_root/labels/train\n","dataset_yaml = {\n","    'path': str(dataset_processed_dir),   # Dataset root directory\n","    'train': 'images/train',              # Relative path to training images\n","    'val': 'images/val',                  # Relative path to validation images\n","    'nc': len(class_names),               # Number of classes\n","    'names': class_names                  # Class names as list (0-indexed)\n","}\n","\n","yaml_path = dataset_processed_dir / 'dataset.yaml'\n","print(\"\\n3. Creating dataset.yaml...\")\n","with open(yaml_path, 'w') as f:\n","    yaml.dump(dataset_yaml, f, default_flow_style=False, sort_keys=False)\n","print(f\"   ‚úì Created: {yaml_path}\")\n","\n","# Display dataset.yaml content\n","print(\"\\n4. dataset.yaml content:\")\n","print(\"   \" + \"=\"*70)\n","with open(yaml_path, 'r') as f:\n","    content = f.read()\n","    for line in content.split('\\n'):\n","        print(f\"   {line}\")\n","print(\"   \" + \"=\"*70)\n","\n","# Verify split and structure\n","print(f\"\\n5. Verifying dataset structure...\")\n","train_img_count = len(list(train_images_dir.glob('*.jpg')))\n","train_lbl_count = len(list(train_labels_dir.glob('*.txt')))\n","val_img_count = len(list(val_images_dir.glob('*.jpg')))\n","val_lbl_count = len(list(val_labels_dir.glob('*.txt')))\n","print(f\"   Train: {train_img_count} images, {train_lbl_count} labels\")\n","print(f\"   Val: {val_img_count} images, {val_lbl_count} labels\")\n","\n","# Verify parallel structure\n","print(f\"\\n6. Verifying YOLOv8 expected structure:\")\n","expected_structure = f\"\"\"\n","{dataset_processed_dir.name}/\n","‚îú‚îÄ‚îÄ images/\n","‚îÇ   ‚îú‚îÄ‚îÄ train/ ({train_img_count} images)\n","‚îÇ   ‚îî‚îÄ‚îÄ val/ ({val_img_count} images)\n","‚îú‚îÄ‚îÄ labels/\n","‚îÇ   ‚îú‚îÄ‚îÄ train/ ({train_lbl_count} labels)\n","‚îÇ   ‚îî‚îÄ‚îÄ val/ ({val_lbl_count} labels)\n","‚îî‚îÄ‚îÄ dataset.yaml\n","\"\"\"\n","print(expected_structure)\n","\n","# Check for mismatches\n","if train_img_count != train_lbl_count:\n","    print(f\"   ‚ö† WARNING: Train mismatch! {train_img_count} images but {train_lbl_count} labels\")\n","if val_img_count != val_lbl_count:\n","    print(f\"   ‚ö† WARNING: Val mismatch! {val_img_count} images but {val_lbl_count} labels\")\n","if train_img_count == train_lbl_count and val_img_count == val_lbl_count:\n","    print(\"   ‚úì Perfect match! All images have corresponding labels\")\n","\n","# Verify at least one label has content\n","print(f\"\\n7. Verifying label content...\")\n","sample_label_list = list(train_labels_dir.glob('*.txt'))\n","if sample_label_list:\n","    sample_label = sample_label_list[0]\n","    with open(sample_label, 'r') as f:\n","        content = f.read()\n","        if content.strip():\n","            print(f\"   ‚úì Sample label ({sample_label.name}) has content:\")\n","            lines = content.strip().split('\\n')[:3]\n","            for line in lines:\n","                print(f\"     {line}\")\n","            if len(content.strip().split('\\n')) > 3:\n","                print(f\"     ... ({len(content.strip().split('\\n'))} total annotations)\")\n","        else:\n","            print(f\"   ‚ö† Sample label is empty!\")\n","else:\n","    print(\"   ‚ö† No label files found in training labels directory!\")\n","\n","print(\"\\n\" + \"=\"*80)\n","print(\"‚úì TRAIN/VAL SPLIT COMPLETED!\")\n","print(\"=\"*80)\n","print(f\"\\nDataset ready for YOLOv8 training!\")\n","print(f\"Next: Run CELL 6 to load model, then CELL 7 to train\")"],"metadata":{"id":"M1Oq0m1A7YMo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1762011492879,"user_tz":-330,"elapsed":17132,"user":{"displayName":"Manvi Sharma","userId":"13719445681117001639"}},"outputId":"80b3035f-5dae-4c9b-ae25-65686d483c5f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["================================================================================\n","CREATING TRAIN/VAL SPLIT\n","================================================================================\n","\n","Total images: 650\n","Training images: 520 (80%)\n","Validation images: 130 (20%)\n","\n","1. Copying training images and labels...\n","   ‚úì Copied 520 training image-label pairs\n","\n","2. Copying validation images and labels...\n","   ‚úì Copied 130 validation image-label pairs\n","\n","3. Creating dataset.yaml...\n","   ‚úì Created: /content/drive/My Drive/YOLO_NWPU_VHR10/NWPU_VHR-10_YOLO_Format/dataset.yaml\n","\n","4. dataset.yaml content:\n","   ======================================================================\n","   path: /content/drive/My Drive/YOLO_NWPU_VHR10/NWPU_VHR-10_YOLO_Format\n","   train: images/train\n","   val: images/val\n","   nc: 10\n","   names:\n","   - airplane\n","   - ship\n","   - storage tank\n","   - baseball diamond\n","   - tennis court\n","   - basketball court\n","   - ground track field\n","   - harbor\n","   - bridge\n","   - vehicle\n","   \n","   ======================================================================\n","\n","5. Verifying dataset structure...\n","   Train: 520 images, 520 labels\n","   Val: 130 images, 130 labels\n","\n","6. Verifying YOLOv8 expected structure:\n","\n","NWPU_VHR-10_YOLO_Format/\n","‚îú‚îÄ‚îÄ images/\n","‚îÇ   ‚îú‚îÄ‚îÄ train/ (520 images)\n","‚îÇ   ‚îî‚îÄ‚îÄ val/ (130 images)\n","‚îú‚îÄ‚îÄ labels/\n","‚îÇ   ‚îú‚îÄ‚îÄ train/ (520 labels)\n","‚îÇ   ‚îî‚îÄ‚îÄ val/ (130 labels)\n","‚îî‚îÄ‚îÄ dataset.yaml\n","\n","   ‚úì Perfect match! All images have corresponding labels\n","\n","7. Verifying label content...\n","   ‚úì Sample label (133.txt) has content:\n","     5 0.385311 0.504195 0.194350 0.149329\n","     5 0.548023 0.517617 0.117514 0.236577\n","     9 0.669492 0.882550 0.048588 0.033557\n","     ... (4 total annotations)\n","\n","================================================================================\n","‚úì TRAIN/VAL SPLIT COMPLETED!\n","================================================================================\n","\n","Dataset ready for YOLOv8 training!\n","Next: Run CELL 6 to load model, then CELL 7 to train\n"]}]},{"cell_type":"code","source":["# ==========================================================================\n","# CELL 5B: COMPUTE CLASS FREQUENCIES AND IDENTIFY MINORITY CLASSES\n","# ==========================================================================\n","from pathlib import Path\n","import json\n","from collections import Counter\n","import numpy as np\n","\n","dataset_processed_dir = Path('/content/drive/My Drive/YOLO_NWPU_VHR10/NWPU_VHR-10_YOLO_Format')\n","train_labels_dir = dataset_processed_dir / 'labels' / 'train'\n","class_names = [\n","    'airplane','ship','storage tank','baseball diamond','tennis court',\n","    'basketball court','ground track field','harbor','bridge','vehicle'\n","]\n","\n","cls_counts = Counter()\n","img_has_class = [Counter() for _ in range(len(class_names))]\n","\n","train_images_dir = dataset_processed_dir / 'images' / 'train'\n","train_images = sorted(list(train_images_dir.glob('*.jpg')))\n","\n","for img_path in train_images:\n","    lbl_path = train_labels_dir / f\"{img_path.stem}.txt\"\n","    if not lbl_path.exists():\n","        continue\n","    seen_in_image = set()\n","    with open(lbl_path, 'r') as f:\n","        for line in f:\n","            parts = line.strip().split()\n","            if len(parts) < 5:\n","                continue\n","            c = int(parts[0])\n","            cls_counts[c] += 1\n","            seen_in_image.add(c)\n","    for c in seen_in_image:\n","        img_has_class[c][img_path.name] += 1\n","\n","total_instances = sum(cls_counts.values())\n","freq = np.zeros(len(class_names), dtype=float)\n","for c in range(len(class_names)):\n","    freq[c] = cls_counts[c] / max(1, total_instances)\n","\n","print(\"Class counts:\")\n","for c in range(len(class_names)):\n","    print(f\"  {class_names[c]}: {cls_counts[c]} instances, freq={freq[c]:.6f}\")\n","\n","# Mark minority classes (e.g., below median frequency)\n","threshold = float(np.median(freq))\n","minority_classes = [c for c in range(len(class_names)) if freq[c] < threshold]\n","print(\"\\nMinority classes (below median frequency):\")\n","for c in minority_classes:\n","    print(f\"  {c} -> {class_names[c]}\")\n","\n","# Save frequencies for later cells\n","np.save(dataset_processed_dir / 'class_freq.npy', freq)\n","with open(dataset_processed_dir / 'minority_classes.json', 'w') as f:\n","    json.dump(minority_classes, f)\n"],"metadata":{"id":"OqtdRNpj8NkQ","executionInfo":{"status":"ok","timestamp":1762011495365,"user_tz":-330,"elapsed":2473,"user":{"displayName":"Manvi Sharma","userId":"13719445681117001639"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"cb21a63b-6170-485e-c15e-aeb4d79d8671"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Class counts:\n","  airplane: 639 instances, freq=0.196434\n","  ship: 246 instances, freq=0.075623\n","  storage tank: 568 instances, freq=0.174608\n","  baseball diamond: 322 instances, freq=0.098986\n","  tennis court: 418 instances, freq=0.128497\n","  basketball court: 133 instances, freq=0.040885\n","  ground track field: 124 instances, freq=0.038119\n","  harbor: 172 instances, freq=0.052874\n","  bridge: 105 instances, freq=0.032278\n","  vehicle: 526 instances, freq=0.161697\n","\n","Minority classes (below median frequency):\n","  1 -> ship\n","  5 -> basketball court\n","  6 -> ground track field\n","  7 -> harbor\n","  8 -> bridge\n"]}]},{"cell_type":"code","source":["\n","# ==========================================================================\n","# SIMPLE: LOAD YOLOv5 MODEL (SMALL OR MEDIUM)\n","# ==========================================================================\n","\n","from ultralytics import YOLO\n","\n","# Choose your model: 'yolov5su.pt' (Small) or 'yolov5mu.pt' (Medium)\n","model_choice = 'yolov5su.pt'  # Change to 'yolov5mu.pt' for medium\n","\n","print(\"=\"*60)\n","print(f\"LOADING YOLOv5 MODEL: {model_choice}\")\n","print(\"=\"*60)\n","\n","# Load pre-trained YOLOv5 model\n","model = YOLO(model_choice)\n","print(\"Model loaded successfully!\")\n","\n","# Show summary of architecture and parameter count\n","print(f\"\\nTotal parameters:       {sum(p.numel() for p in model.model.parameters())}\")\n","print(f\"Trainable parameters:   {sum(p.numel() for p in model.model.parameters() if p.requires_grad)}\")\n","print(f\"\\nModel Architecture:\\n{model.model}\")"],"metadata":{"id":"XKL0yqjS7YKK","executionInfo":{"status":"ok","timestamp":1762011496311,"user_tz":-330,"elapsed":949,"user":{"displayName":"Manvi Sharma","userId":"13719445681117001639"}},"collapsed":true,"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e9cc39d8-b420-42e5-8d2c-75a185af2316"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Creating new Ultralytics Settings v0.0.6 file ‚úÖ \n","View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n","Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n","============================================================\n","LOADING YOLOv5 MODEL: yolov5su.pt\n","============================================================\n","\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov5su.pt to 'yolov5su.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 17.7MB 128.5MB/s 0.1s\n","Model loaded successfully!\n","\n","Total parameters:       9153152\n","Trainable parameters:   0\n","\n","Model Architecture:\n","DetectionModel(\n","  (model): Sequential(\n","    (0): Conv(\n","      (conv): Conv2d(3, 32, kernel_size=(6, 6), stride=(2, 2), padding=(2, 2), bias=False)\n","      (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","      (act): SiLU(inplace=True)\n","    )\n","    (1): Conv(\n","      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","      (act): SiLU(inplace=True)\n","    )\n","    (2): C3(\n","      (cv1): Conv(\n","        (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","      (cv2): Conv(\n","        (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","      (cv3): Conv(\n","        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","      (m): Sequential(\n","        (0): Bottleneck(\n","          (cv1): Conv(\n","            (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","          (cv2): Conv(\n","            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","        )\n","      )\n","    )\n","    (3): Conv(\n","      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","      (act): SiLU(inplace=True)\n","    )\n","    (4): C3(\n","      (cv1): Conv(\n","        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","      (cv2): Conv(\n","        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","      (cv3): Conv(\n","        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","      (m): Sequential(\n","        (0): Bottleneck(\n","          (cv1): Conv(\n","            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","          (cv2): Conv(\n","            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","        )\n","        (1): Bottleneck(\n","          (cv1): Conv(\n","            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","          (cv2): Conv(\n","            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","        )\n","      )\n","    )\n","    (5): Conv(\n","      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","      (act): SiLU(inplace=True)\n","    )\n","    (6): C3(\n","      (cv1): Conv(\n","        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","      (cv2): Conv(\n","        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","      (cv3): Conv(\n","        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","      (m): Sequential(\n","        (0): Bottleneck(\n","          (cv1): Conv(\n","            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","          (cv2): Conv(\n","            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","        )\n","        (1): Bottleneck(\n","          (cv1): Conv(\n","            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","          (cv2): Conv(\n","            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","        )\n","        (2): Bottleneck(\n","          (cv1): Conv(\n","            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","          (cv2): Conv(\n","            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","        )\n","      )\n","    )\n","    (7): Conv(\n","      (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","      (act): SiLU(inplace=True)\n","    )\n","    (8): C3(\n","      (cv1): Conv(\n","        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","      (cv2): Conv(\n","        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","      (cv3): Conv(\n","        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","      (m): Sequential(\n","        (0): Bottleneck(\n","          (cv1): Conv(\n","            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","          (cv2): Conv(\n","            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","        )\n","      )\n","    )\n","    (9): SPPF(\n","      (cv1): Conv(\n","        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","      (cv2): Conv(\n","        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","      (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n","    )\n","    (10): Conv(\n","      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","      (act): SiLU(inplace=True)\n","    )\n","    (11): Upsample(scale_factor=2.0, mode='nearest')\n","    (12): Concat()\n","    (13): C3(\n","      (cv1): Conv(\n","        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","      (cv2): Conv(\n","        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","      (cv3): Conv(\n","        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","      (m): Sequential(\n","        (0): Bottleneck(\n","          (cv1): Conv(\n","            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","          (cv2): Conv(\n","            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","        )\n","      )\n","    )\n","    (14): Conv(\n","      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","      (act): SiLU(inplace=True)\n","    )\n","    (15): Upsample(scale_factor=2.0, mode='nearest')\n","    (16): Concat()\n","    (17): C3(\n","      (cv1): Conv(\n","        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","      (cv2): Conv(\n","        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","      (cv3): Conv(\n","        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","      (m): Sequential(\n","        (0): Bottleneck(\n","          (cv1): Conv(\n","            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","          (cv2): Conv(\n","            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","        )\n","      )\n","    )\n","    (18): Conv(\n","      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","      (act): SiLU(inplace=True)\n","    )\n","    (19): Concat()\n","    (20): C3(\n","      (cv1): Conv(\n","        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","      (cv2): Conv(\n","        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","      (cv3): Conv(\n","        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","      (m): Sequential(\n","        (0): Bottleneck(\n","          (cv1): Conv(\n","            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","          (cv2): Conv(\n","            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","        )\n","      )\n","    )\n","    (21): Conv(\n","      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","      (act): SiLU(inplace=True)\n","    )\n","    (22): Concat()\n","    (23): C3(\n","      (cv1): Conv(\n","        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","      (cv2): Conv(\n","        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","      (cv3): Conv(\n","        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU(inplace=True)\n","      )\n","      (m): Sequential(\n","        (0): Bottleneck(\n","          (cv1): Conv(\n","            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","          (cv2): Conv(\n","            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","        )\n","      )\n","    )\n","    (24): Detect(\n","      (cv2): ModuleList(\n","        (0): Sequential(\n","          (0): Conv(\n","            (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","          (1): Conv(\n","            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","          (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n","        )\n","        (1): Sequential(\n","          (0): Conv(\n","            (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","          (1): Conv(\n","            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","          (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n","        )\n","        (2): Sequential(\n","          (0): Conv(\n","            (conv): Conv2d(512, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","          (1): Conv(\n","            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","          (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n","        )\n","      )\n","      (cv3): ModuleList(\n","        (0): Sequential(\n","          (0): Conv(\n","            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","          (1): Conv(\n","            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","          (2): Conv2d(128, 80, kernel_size=(1, 1), stride=(1, 1))\n","        )\n","        (1): Sequential(\n","          (0): Conv(\n","            (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","          (1): Conv(\n","            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","          (2): Conv2d(128, 80, kernel_size=(1, 1), stride=(1, 1))\n","        )\n","        (2): Sequential(\n","          (0): Conv(\n","            (conv): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","          (1): Conv(\n","            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU(inplace=True)\n","          )\n","          (2): Conv2d(128, 80, kernel_size=(1, 1), stride=(1, 1))\n","        )\n","      )\n","      (dfl): DFL(\n","        (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      )\n","    )\n","  )\n",")\n"]}]},{"cell_type":"code","source":["# ==========================================================================\n","# REBUILD train_expanded_list.txt FROM CURRENT TRAIN SPLIT\n","# (Run this BEFORE your materialize cell)\n","# ==========================================================================\n","from pathlib import Path\n","import numpy as np\n","import math\n","import json\n","\n","dataset_processed_dir = Path('/content/drive/My Drive/YOLO_NWPU_VHR10/NWPU_VHR-10_YOLO_Format')\n","train_images_dir = dataset_processed_dir / 'images' / 'train'\n","train_labels_dir = dataset_processed_dir / 'labels' / 'train'\n","\n","# If you previously computed class frequencies, load them; otherwise compute quickly here\n","class_names = [\n","    'airplane','ship','storage tank','baseball diamond','tennis court',\n","    'basketball court','ground track field','harbor','bridge','vehicle'\n","]\n","C = len(class_names)\n","\n","# Compute class frequencies from labels\n","cls_counts = [0]*C\n","total_instances = 0\n","for img_path in sorted(train_images_dir.glob('*.jpg')):\n","    lbl_path = train_labels_dir / f\"{img_path.stem}.txt\"\n","    if not lbl_path.exists():\n","        continue\n","    with open(lbl_path, 'r') as f:\n","        for line in f:\n","            parts = line.strip().split()\n","            if len(parts) < 5:\n","                continue\n","            c = int(parts[0])\n","            if 0 <= c < C:\n","                cls_counts[c] += 1\n","                total_instances += 1\n","\n","freq = np.array([(cnt / total_instances) if total_instances > 0 else 0.0 for cnt in cls_counts], dtype=float)\n","print(\"Class frequencies:\", freq)\n","\n","# Repeat-Factor parameters\n","t = 0.005\n","\n","def repeat_factor_for_class(fc):\n","    if fc <= 0:\n","        return 1.0\n","    return max(1.0, math.sqrt(t / fc))\n","\n","class_rf = [repeat_factor_for_class(fc) for fc in freq]\n","\n","# Build expanded list\n","expanded = []\n","for img_path in sorted(train_images_dir.glob('*.jpg')):\n","    lbl_path = train_labels_dir / f\"{img_path.stem}.txt\"\n","    if not lbl_path.exists():\n","        continue\n","    present = set()\n","    with open(lbl_path, 'r') as f:\n","        for line in f:\n","            parts = line.strip().split()\n","            if len(parts) < 5:\n","                continue\n","            c = int(parts[0])\n","            if 0 <= c < C:\n","                present.add(c)\n","    rf_img = max([class_rf[c] for c in present], default=1.0)\n","    k = int(math.floor(rf_img))\n","    p = rf_img - k\n","    reps = k + (1 if np.random.rand() < p else 0)\n","    reps = max(1, reps)\n","    expanded.extend([img_path.name]*reps)\n","\n","expanded_list_path = dataset_processed_dir / 'train_expanded_list.txt'\n","with open(expanded_list_path, 'w') as f:\n","    for name in expanded:\n","        f.write(name + '\\n')\n","\n","print(f\"Saved: {expanded_list_path} | entries={len(expanded)} | unique={len(set(expanded))}\")\n"],"metadata":{"id":"OLyvMYINBNwc","executionInfo":{"status":"ok","timestamp":1762011499224,"user_tz":-330,"elapsed":2910,"user":{"displayName":"Manvi Sharma","userId":"13719445681117001639"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"89cdc528-c792-4e41-ca78-8d91be151e3a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Class frequencies: [    0.19643    0.075623     0.17461    0.098986      0.1285    0.040885    0.038119    0.052874    0.032278      0.1617]\n","Saved: /content/drive/My Drive/YOLO_NWPU_VHR10/NWPU_VHR-10_YOLO_Format/train_expanded_list.txt | entries=520 | unique=520\n"]}]},{"cell_type":"code","source":["# ==========================================================================\n","# CELL 6B (ALTERNATIVE): MATERIALIZE REPEATED TRAIN SPLIT\n","# ==========================================================================\n","from pathlib import Path\n","import shutil\n","\n","dataset_processed_dir = Path('/content/drive/My Drive/YOLO_NWPU_VHR10/NWPU_VHR-10_YOLO_Format')\n","train_images_dir = dataset_processed_dir / 'images' / 'train'\n","train_labels_dir = dataset_processed_dir / 'labels' / 'train'\n","\n","bal_images_dir = dataset_processed_dir / 'images' / 'train_bal'\n","bal_labels_dir = dataset_processed_dir / 'labels' / 'train_bal'\n","bal_images_dir.mkdir(parents=True, exist_ok=True)\n","bal_labels_dir.mkdir(parents=True, exist_ok=True)\n","\n","expanded_list_path = dataset_processed_dir / 'train_expanded_list.txt'\n","with open(expanded_list_path, 'r') as f:\n","    expanded_train_names = [line.strip() for line in f if line.strip()]\n","\n","# Populate balanced split by copying with unique suffixes\n","counter = {}\n","for name in expanded_train_names:\n","    stem = Path(name).stem\n","    counter[stem] = counter.get(stem, 0) + 1\n","    k = counter[stem]\n","    src_img = train_images_dir / name\n","    src_lbl = train_labels_dir / f\"{stem}.txt\"\n","    if not src_img.exists() or not src_lbl.exists():\n","        continue\n","    dst_img = bal_images_dir / f\"{stem}__rep{k}.jpg\"\n","    dst_lbl = bal_labels_dir / f\"{stem}__rep{k}.txt\"\n","    shutil.copy2(src_img, dst_img)\n","    shutil.copy2(src_lbl, dst_lbl)\n","\n","print(f\"Balanced train images: {len(list(bal_images_dir.glob('*.jpg')))}\")\n","print(f\"Balanced train labels: {len(list(bal_labels_dir.glob('*.txt')))}\")\n"],"metadata":{"id":"eV8O7ruW7qrq","executionInfo":{"status":"ok","timestamp":1762011512532,"user_tz":-330,"elapsed":13305,"user":{"displayName":"Manvi Sharma","userId":"13719445681117001639"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"068c1735-8e27-4a81-94f3-270a8a19e331"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Balanced train images: 520\n","Balanced train labels: 520\n"]}]},{"cell_type":"code","source":["# ==========================================================================\n","# CELL 7 (ALTERNATIVE): TRAIN USING MATERIALIZED BALANCED SPLIT\n","# ==========================================================================\n","from ultralytics import YOLO\n","from pathlib import Path\n","import yaml\n","import shutil\n","\n","dataset_processed_dir = Path('/content/drive/My Drive/YOLO_NWPU_VHR10/NWPU_VHR-10_YOLO_Format')\n","yaml_path = dataset_processed_dir / 'dataset.yaml'\n","with open(yaml_path, 'r') as f:\n","    ds_cfg = yaml.safe_load(f)\n","\n","# Create a temporary yaml that uses the balanced train split\n","tmp_yaml = dataset_processed_dir / 'dataset_balanced.yaml'\n","ds_bal = dict(ds_cfg)\n","ds_bal['train'] = 'images/train_bal'  # use balanced split\n","ds_bal['val'] = 'images/val'          # keep validation untouched\n","with open(tmp_yaml, 'w') as f:\n","    yaml.safe_dump(ds_bal, f, sort_keys=False)\n","\n","models_dir = Path('/content/drive/My Drive/YOLO_NWPU_VHR10/Models')\n","runs_dir = Path('/content/drive/My Drive/YOLO_NWPU_VHR10/Training_Runs')\n","\n","model = YOLO('yolov5su.pt')\n","results = model.train(\n","    data=str(tmp_yaml),\n","    epochs=120,\n","    imgsz=640,\n","    batch=16,\n","    patience=40,\n","    device=0,\n","\n","    lr0=0.001,\n","    lrf=0.01,\n","    momentum=0.937,\n","    weight_decay=0.0005,\n","    optimizer='SGD',\n","    warmup_epochs=5,\n","    warmup_momentum=0.8,\n","    warmup_bias_lr=0.1,\n","\n","    mosaic=1.0,\n","    mixup=0.15,\n","    copy_paste=0.3,\n","    degrees=45,\n","    translate=0.15,\n","    scale=0.5,\n","    flipud=0.5,\n","    fliplr=0.5,\n","    perspective=0.0001,\n","    hsv_h=0.015,\n","    hsv_s=0.7,\n","    hsv_v=0.4,\n","\n","    save=True,\n","    save_period=10,\n","    val=True,\n","    verbose=True,\n","    project=str(runs_dir),\n","    name='NWPU_VHR10_yolov5_balanced_materialized',\n","    exist_ok=False,\n",")\n","\n","print(\"\\nTraining finished.\")\n","best_model_path = Path(results.save_dir) / 'weights' / 'best.pt'\n","if best_model_path.exists():\n","    dest = models_dir / 'yolov5_nwpu_vhr_10_best_balanced.pt'\n","    shutil.copy2(best_model_path, dest)\n","    print(f\"Saved best model: {dest}\")"],"metadata":{"id":"NT7PQ_Yk_jDd","executionInfo":{"status":"ok","timestamp":1762013581430,"user_tz":-330,"elapsed":2068890,"user":{"displayName":"Manvi Sharma","userId":"13719445681117001639"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9338a837-1d46-4411-bd84-6854fb9105a3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics 8.3.223 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.3, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/My Drive/YOLO_NWPU_VHR10/NWPU_VHR-10_YOLO_Format/dataset_balanced.yaml, degrees=45, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=120, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.5, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.15, mode=train, model=yolov5su.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=NWPU_VHR10_yolov5_balanced_materialized, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=40, perspective=0.0001, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/My Drive/YOLO_NWPU_VHR10/Training_Runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/My Drive/YOLO_NWPU_VHR10/Training_Runs/NWPU_VHR10_yolov5_balanced_materialized, save_frames=False, save_json=False, save_period=10, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.15, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=5, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 755.1KB 26.3MB/s 0.0s\n","Overriding model.yaml nc=80 with nc=10\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      3520  ultralytics.nn.modules.conv.Conv             [3, 32, 6, 2, 2]              \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     18816  ultralytics.nn.modules.block.C3              [64, 64, 1]                   \n","  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  4                  -1  2    115712  ultralytics.nn.modules.block.C3              [128, 128, 2]                 \n","  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  6                  -1  3    625152  ultralytics.nn.modules.block.C3              [256, 256, 3]                 \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1]                 \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1]              \n"," 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 13                  -1  1    361984  ultralytics.nn.modules.block.C3              [512, 256, 1, False]          \n"," 14                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \n"," 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 17                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \n"," 18                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 20                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \n"," 21                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 23                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1, False]          \n"," 24        [17, 20, 23]  1   2119918  ultralytics.nn.modules.head.Detect           [10, [128, 256, 512]]         \n","YOLOv5s summary: 153 layers, 9,126,062 parameters, 9,126,046 gradients, 24.1 GFLOPs\n","\n","Transferred 421/427 items from pretrained weights\n","Freezing layer 'model.24.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5.4MB 86.8MB/s 0.1s\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.6¬±0.2 ms, read: 50.8¬±12.9 MB/s, size: 86.9 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/My Drive/YOLO_NWPU_VHR10/NWPU_VHR-10_YOLO_Format/labels/train_bal... 520 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 520/520 79.2it/s 6.6s\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/My Drive/YOLO_NWPU_VHR10/NWPU_VHR-10_YOLO_Format/labels/train_bal.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 2.3¬±2.1 ms, read: 22.8¬±23.6 MB/s, size: 85.3 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/My Drive/YOLO_NWPU_VHR10/NWPU_VHR-10_YOLO_Format/labels/val... 130 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 130/130 57.9it/s 2.2s\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/My Drive/YOLO_NWPU_VHR10/NWPU_VHR-10_YOLO_Format/labels/val.cache\n","Plotting labels to /content/drive/My Drive/YOLO_NWPU_VHR10/Training_Runs/NWPU_VHR10_yolov5_balanced_materialized/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.001, momentum=0.937) with parameter groups 69 weight(decay=0.0), 76 weight(decay=0.0005), 75 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/content/drive/My Drive/YOLO_NWPU_VHR10/Training_Runs/NWPU_VHR10_yolov5_balanced_materialized\u001b[0m\n","Starting training for 120 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      1/120      3.89G      2.599      4.882      2.087        101        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.2it/s 15.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 1.2it/s 4.1s\n","                   all        130        668     0.0444     0.0602     0.0257     0.0168\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      2/120      4.71G      2.374      3.964      1.928        136        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.7it/s 12.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.5it/s 2.0s\n","                   all        130        668      0.247      0.171      0.159     0.0876\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      3/120      4.73G      2.111      2.777      1.752         84        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.4it/s 13.6s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.7it/s 1.9s\n","                   all        130        668      0.522      0.344      0.347      0.155\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      4/120      4.76G       1.97      2.372      1.687         84        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.5it/s 13.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.3it/s 2.2s\n","                   all        130        668      0.754      0.434      0.437      0.158\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      5/120      4.77G      1.833      1.988      1.537        105        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.8it/s 11.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.0it/s 2.5s\n","                   all        130        668      0.693      0.519      0.526      0.207\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      6/120       4.8G      1.754      1.859       1.49        160        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.5it/s 13.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.6it/s 1.9s\n","                   all        130        668      0.707      0.551      0.573      0.198\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      7/120      4.82G      1.662       1.71      1.451         73        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.5it/s 13.4s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.7it/s 1.8s\n","                   all        130        668      0.765      0.635      0.676      0.265\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      8/120      4.84G       1.61      1.597      1.408        130        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.6it/s 12.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.2it/s 1.6s\n","                   all        130        668      0.719      0.665      0.683      0.273\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      9/120      4.86G      1.602      1.544      1.425         67        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.5it/s 13.4s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.0it/s 1.7s\n","                   all        130        668      0.766      0.675      0.691      0.296\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     10/120      4.88G      1.522      1.376      1.334         80        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.5it/s 13.4s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.9it/s 1.7s\n","                   all        130        668      0.679      0.655      0.657      0.326\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     11/120       4.9G      1.494      1.319      1.345         85        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.6it/s 12.8s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.9it/s 1.7s\n","                   all        130        668      0.776      0.713      0.759      0.366\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     12/120      4.92G      1.483      1.279      1.303         91        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.6it/s 12.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.4it/s 2.1s\n","                   all        130        668      0.748      0.723      0.737      0.333\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     13/120      4.94G      1.464      1.229       1.29        105        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.5it/s 13.1s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.8it/s 1.8s\n","                   all        130        668      0.755      0.727      0.738      0.374\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     14/120      4.97G       1.43      1.161      1.272         96        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.4it/s 13.6s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.2it/s 1.6s\n","                   all        130        668      0.784      0.752      0.775      0.406\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     15/120      4.99G      1.441      1.182      1.262         76        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.4it/s 13.5s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.0it/s 1.7s\n","                   all        130        668       0.78       0.79      0.781      0.427\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     16/120      5.01G       1.43      1.185      1.285         55        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.5it/s 13.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.0it/s 1.7s\n","                   all        130        668      0.772      0.746      0.787      0.421\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     17/120      5.03G      1.363      1.095      1.228        155        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.6it/s 12.5s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.9it/s 1.7s\n","                   all        130        668      0.794      0.765      0.788      0.403\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     18/120      5.05G      1.422      1.145      1.252        112        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.6it/s 12.8s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.5it/s 2.0s\n","                   all        130        668      0.775      0.778      0.802      0.421\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     19/120      5.07G      1.354      1.043      1.228        113        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.5it/s 13.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.3it/s 2.2s\n","                   all        130        668      0.818      0.787      0.838       0.47\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     20/120      5.09G      1.364       1.08      1.224        119        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.4it/s 13.8s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.1it/s 1.6s\n","                   all        130        668      0.777        0.8      0.833       0.49\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     21/120      5.11G      1.358       1.08       1.23        112        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.5it/s 13.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.0it/s 1.7s\n","                   all        130        668      0.816      0.829      0.847       0.48\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     22/120      5.13G      1.334      1.004      1.186        172        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.5it/s 13.5s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.0it/s 1.7s\n","                   all        130        668      0.829      0.832       0.85      0.509\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     23/120      5.15G      1.349      1.004      1.201        109        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.5it/s 13.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.2it/s 1.6s\n","                   all        130        668      0.796      0.855       0.85      0.514\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     24/120      5.18G      1.347      1.015      1.197        163        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.4it/s 13.8s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.8it/s 1.8s\n","                   all        130        668      0.826      0.849      0.859      0.513\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     25/120      5.19G      1.315     0.9818      1.177         85        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.5it/s 13.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.3it/s 2.2s\n","                   all        130        668      0.864      0.822      0.875      0.519\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     26/120      5.22G      1.312      0.978       1.19         57        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.2it/s 14.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.1it/s 1.6s\n","                   all        130        668       0.81       0.85      0.866      0.489\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     27/120      5.24G      1.338     0.9828      1.184        133        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.2it/s 14.8s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.2it/s 1.5s\n","                   all        130        668      0.839      0.856      0.869      0.507\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     28/120      5.26G      1.302     0.9499      1.159         99        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.3it/s 14.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.3it/s 1.5s\n","                   all        130        668      0.848       0.85      0.865      0.524\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     29/120      5.28G        1.3     0.9352      1.179         59        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.1it/s 15.4s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 1.9it/s 2.6s\n","                   all        130        668      0.826      0.853       0.86      0.535\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     30/120       5.3G        1.3     0.9192      1.153        103        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.3it/s 14.5s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.4it/s 1.5s\n","                   all        130        668      0.838      0.862      0.873      0.549\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     31/120      5.32G      1.271     0.9096      1.142         94        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.2it/s 14.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.1it/s 1.6s\n","                   all        130        668      0.825      0.835      0.869      0.553\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     32/120      5.34G      1.308      0.948      1.181         85        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.2it/s 15.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.8it/s 1.8s\n","                   all        130        668      0.813      0.881      0.884      0.575\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     33/120      5.36G      1.288      0.911      1.171        150        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.3it/s 14.5s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.2it/s 2.3s\n","                   all        130        668      0.854      0.892       0.89       0.58\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     34/120      5.39G      1.299     0.9431      1.175        125        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.3it/s 14.4s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.3it/s 1.5s\n","                   all        130        668      0.845      0.867      0.894      0.555\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     35/120      5.41G      1.284      0.899      1.161        149        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.4it/s 13.8s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.4it/s 1.5s\n","                   all        130        668      0.851      0.882      0.904      0.582\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     36/120      5.43G      1.246     0.8637      1.133        106        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.2it/s 14.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.1it/s 1.6s\n","                   all        130        668       0.82      0.876      0.885      0.577\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     37/120      5.45G      1.332     0.9535      1.174         96        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.2it/s 14.7s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.1it/s 2.3s\n","                   all        130        668      0.856      0.887      0.903      0.596\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     38/120      5.47G      1.253     0.8529      1.122        157        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.3it/s 14.5s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.9it/s 1.7s\n","                   all        130        668      0.849      0.888        0.9      0.604\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     39/120      5.49G      1.265     0.8779      1.137        128        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.2it/s 15.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.4it/s 1.5s\n","                   all        130        668      0.879      0.861      0.898      0.616\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     40/120      5.51G      1.272     0.8899      1.129        127        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.2it/s 15.1s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.6it/s 1.9s\n","                   all        130        668      0.868      0.875      0.907      0.625\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     41/120      5.53G      1.274      0.888      1.143         86        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.2it/s 15.1s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.9it/s 1.7s\n","                   all        130        668      0.854      0.885        0.9       0.62\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     42/120      5.55G      1.248     0.8623       1.14         78        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.4it/s 13.5s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.0it/s 1.6s\n","                   all        130        668      0.849      0.895      0.901      0.607\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     43/120      5.58G      1.205     0.8183      1.113        147        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.4it/s 13.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.0it/s 1.7s\n","                   all        130        668      0.853       0.89      0.906      0.597\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     44/120       5.6G      1.222     0.8363       1.11         82        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.4it/s 14.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.0it/s 1.7s\n","                   all        130        668      0.873      0.857      0.906      0.632\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     45/120      5.62G      1.216     0.8289      1.129         78        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.2it/s 15.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 1.9it/s 2.6s\n","                   all        130        668      0.875      0.884      0.909      0.615\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     46/120      5.64G      1.222     0.8261      1.107         54        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.3it/s 14.4s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.8it/s 1.8s\n","                   all        130        668      0.854      0.897       0.91      0.629\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     47/120      5.66G      1.215       0.82      1.128        107        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.4it/s 13.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.0it/s 1.6s\n","                   all        130        668      0.884      0.876      0.917      0.632\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     48/120      5.68G      1.219      0.829      1.115        100        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.3it/s 14.5s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.4it/s 1.5s\n","                   all        130        668       0.87      0.893       0.91      0.625\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     49/120       5.7G      1.206     0.8225      1.131         87        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.4it/s 13.8s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.7it/s 1.9s\n","                   all        130        668      0.867      0.881      0.908      0.634\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     50/120      5.72G      1.199     0.7976      1.104        137        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.3it/s 14.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.0it/s 2.5s\n","                   all        130        668      0.871      0.885      0.914      0.627\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     51/120      5.74G      1.242     0.8274      1.124         73        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.3it/s 14.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.2it/s 1.6s\n","                   all        130        668      0.886      0.896      0.914      0.619\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     52/120      5.77G      1.234     0.8468      1.119        141        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.3it/s 14.6s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.9it/s 1.7s\n","                   all        130        668      0.874       0.88      0.907      0.637\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     53/120       6.1G      1.208     0.8031      1.116         81        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.4it/s 14.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.0it/s 1.6s\n","                   all        130        668      0.877      0.909      0.923      0.638\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     54/120      6.13G      1.202     0.8176      1.114         42        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.2it/s 14.8s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.0it/s 2.4s\n","                   all        130        668      0.881      0.901       0.92      0.636\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     55/120      6.15G      1.181     0.7977      1.106         78        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.3it/s 14.1s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.7it/s 1.9s\n","                   all        130        668      0.886      0.896      0.928      0.638\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     56/120      6.17G      1.188      0.785      1.086         92        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.2it/s 14.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.1it/s 1.6s\n","                   all        130        668      0.877      0.911      0.921      0.647\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     57/120      6.19G      1.205      0.796      1.106        102        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.2it/s 15.1s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.9it/s 1.7s\n","                   all        130        668       0.84      0.914      0.922      0.645\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     58/120      6.21G      1.189     0.7769      1.103         90        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.4it/s 13.6s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.2it/s 2.3s\n","                   all        130        668      0.867      0.906      0.927      0.638\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     59/120      6.23G      1.185     0.7917        1.1        175        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.4it/s 13.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.4it/s 2.1s\n","                   all        130        668      0.867      0.911      0.925      0.644\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     60/120      6.25G       1.16     0.7776      1.104         92        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.4it/s 13.7s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.9it/s 1.7s\n","                   all        130        668      0.874      0.907      0.939      0.655\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     61/120      6.27G      1.231     0.8071       1.11        107        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.3it/s 14.6s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.8it/s 1.8s\n","                   all        130        668      0.896      0.903      0.934      0.647\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     62/120       6.3G      1.169     0.7508      1.094        110        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.4it/s 13.7s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.2it/s 1.5s\n","                   all        130        668      0.891      0.893      0.924      0.631\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     63/120      6.32G      1.186     0.7736      1.102        103        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.5it/s 13.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.3it/s 2.2s\n","                   all        130        668      0.886      0.905      0.924      0.655\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     64/120      6.34G      1.185     0.7915      1.104        132        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.2it/s 15.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.0it/s 1.7s\n","                   all        130        668      0.887      0.919      0.933      0.661\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     65/120      6.36G      1.186     0.7518      1.081        105        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.3it/s 14.6s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.0it/s 1.7s\n","                   all        130        668      0.897      0.903      0.936      0.673\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     66/120      6.38G      1.185     0.7767      1.109         86        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.3it/s 14.6s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.8it/s 1.8s\n","                   all        130        668      0.902      0.924      0.936      0.658\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     67/120       6.4G      1.198      0.789      1.116        112        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.4it/s 13.7s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.4it/s 2.1s\n","                   all        130        668      0.912      0.904      0.937       0.67\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     68/120      6.42G      1.179     0.7436      1.086         82        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.4it/s 14.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.8it/s 1.8s\n","                   all        130        668       0.91      0.903      0.937      0.662\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     69/120      6.44G      1.176     0.7878      1.095         84        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.3it/s 14.5s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.5it/s 1.4s\n","                   all        130        668      0.921      0.892      0.925      0.658\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     70/120      6.46G      1.152     0.7649      1.094         74        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.3it/s 14.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.9it/s 1.7s\n","                   all        130        668      0.901      0.914      0.928      0.663\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     71/120      6.48G      1.151     0.7528      1.087         90        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.4it/s 13.7s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.7it/s 1.8s\n","                   all        130        668      0.922      0.905      0.937      0.673\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     72/120      6.51G      1.149     0.7324      1.085        155        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.4it/s 13.8s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.9it/s 1.7s\n","                   all        130        668      0.909      0.891      0.933      0.653\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     73/120      6.52G      1.141     0.7395      1.092         75        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.5it/s 13.1s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.3it/s 2.2s\n","                   all        130        668      0.908      0.894       0.93       0.65\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     74/120      6.55G      1.153     0.7562      1.098         52        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.3it/s 14.5s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.3it/s 1.5s\n","                   all        130        668       0.89      0.897      0.927      0.651\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     75/120      6.57G       1.16     0.7595      1.093         47        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.4it/s 13.6s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.2it/s 1.5s\n","                   all        130        668      0.916       0.88      0.928      0.662\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     76/120      6.59G      1.179     0.7509       1.09        141        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.3it/s 14.1s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.9it/s 1.7s\n","                   all        130        668      0.892      0.881      0.923      0.655\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     77/120      6.61G      1.164     0.7628      1.098         56        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.4it/s 13.5s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.0it/s 1.7s\n","                   all        130        668      0.901      0.872      0.918      0.662\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     78/120      6.63G      1.168      0.764      1.095         60        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.4it/s 14.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.4it/s 2.1s\n","                   all        130        668      0.921      0.881       0.93      0.665\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     79/120      6.65G      1.146     0.7485      1.083        115        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.5it/s 13.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.2it/s 2.3s\n","                   all        130        668      0.923      0.876      0.933      0.663\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     80/120      6.67G       1.13     0.7206      1.067        121        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.3it/s 14.1s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.0it/s 1.7s\n","                   all        130        668      0.896      0.903      0.933      0.659\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     81/120      6.69G      1.133     0.7229      1.074         67        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.5it/s 13.4s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.3it/s 1.5s\n","                   all        130        668      0.908      0.887      0.925      0.662\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     82/120      6.72G      1.138      0.714      1.073        151        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.4it/s 14.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.1it/s 1.6s\n","                   all        130        668       0.89      0.881      0.925      0.658\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     83/120      6.74G      1.157      0.744      1.092         75        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.5it/s 13.5s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.2it/s 1.6s\n","                   all        130        668       0.87      0.904      0.927      0.656\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     84/120      6.76G      1.102     0.6971      1.055         92        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.4it/s 13.7s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.3it/s 2.2s\n","                   all        130        668      0.878      0.906      0.926      0.664\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     85/120      6.78G      1.149     0.7268      1.073        181        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.4it/s 13.6s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.3it/s 2.1s\n","                   all        130        668      0.877      0.908      0.927      0.658\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     86/120       6.8G      1.123     0.7306      1.068         65        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.3it/s 14.1s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.7it/s 1.9s\n","                   all        130        668      0.913      0.882      0.932      0.663\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     87/120      6.82G      1.103     0.7098      1.076         85        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.3it/s 14.1s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.7it/s 1.9s\n","                   all        130        668      0.906      0.885      0.933      0.659\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     88/120      6.84G      1.112     0.7169      1.069         60        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.4it/s 13.6s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.1it/s 1.6s\n","                   all        130        668      0.898      0.897      0.933      0.664\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     89/120      6.86G      1.116     0.7007      1.065        103        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.4it/s 14.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.6it/s 1.9s\n","                   all        130        668      0.918      0.889      0.932      0.662\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     90/120      6.88G      1.125     0.7176       1.08        146        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.4it/s 14.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.6it/s 1.9s\n","                   all        130        668      0.917      0.887      0.927      0.665\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     91/120      6.91G       1.13     0.7234       1.08        181        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.3it/s 14.5s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.2it/s 1.5s\n","                   all        130        668      0.916      0.887      0.931      0.671\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     92/120      6.93G      1.106      0.723      1.074         72        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.5it/s 13.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.6it/s 1.4s\n","                   all        130        668      0.899      0.896      0.928      0.667\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     93/120      7.17G      1.113     0.7049      1.072         79        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.3it/s 14.4s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.8it/s 1.8s\n","                   all        130        668       0.92      0.879      0.927       0.66\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     94/120      7.19G      1.089      0.693       1.05        125        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.4it/s 13.6s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.0it/s 1.7s\n","                   all        130        668      0.919      0.886      0.932      0.666\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     95/120      7.21G      1.119     0.7138      1.069         78        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.3it/s 14.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.2it/s 2.3s\n","                   all        130        668      0.895      0.898      0.936      0.672\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     96/120      7.23G      1.113     0.7105      1.076         89        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.4it/s 13.8s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.3it/s 2.2s\n","                   all        130        668      0.901      0.918      0.941      0.669\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     97/120      7.25G      1.115     0.6986      1.061         94        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.3it/s 14.1s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.2it/s 1.5s\n","                   all        130        668      0.915      0.902      0.939      0.675\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     98/120      7.28G      1.113      0.714      1.071        114        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.3it/s 14.5s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.1it/s 1.6s\n","                   all        130        668       0.94      0.881      0.935      0.679\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     99/120       7.3G      1.093      0.695      1.075         68        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.3it/s 14.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.3it/s 1.5s\n","                   all        130        668      0.933      0.891      0.935      0.677\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K    100/120      7.32G      1.121     0.7025      1.059         86        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.5it/s 13.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.1it/s 2.4s\n","                   all        130        668      0.917        0.9      0.929      0.672\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K    101/120      7.34G       1.09     0.6933      1.075        228        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.4it/s 13.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.1it/s 1.6s\n","                   all        130        668      0.908       0.91      0.935      0.667\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K    102/120      7.36G      1.109     0.6951      1.058         69        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.3it/s 14.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.1it/s 1.6s\n","                   all        130        668      0.916       0.89      0.933      0.672\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K    103/120      7.38G       1.11     0.7104       1.07         77        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.3it/s 14.1s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.3it/s 1.5s\n","                   all        130        668       0.93      0.885      0.929      0.678\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K    104/120      3.79G      1.089     0.6967      1.056         46        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.5it/s 13.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.3it/s 1.5s\n","                   all        130        668       0.93      0.892      0.932      0.679\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K    105/120      3.79G      1.105     0.7073      1.077         89        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.4it/s 13.8s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.0it/s 2.5s\n","                   all        130        668      0.922      0.889      0.928      0.678\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K    106/120      3.79G      1.088     0.6931      1.061         79        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.3it/s 14.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.1it/s 1.6s\n","                   all        130        668      0.918      0.891      0.931      0.674\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K    107/120      3.98G      1.076     0.6688      1.052         92        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.5it/s 13.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.0it/s 1.7s\n","                   all        130        668      0.922      0.893      0.931      0.674\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K    108/120      3.98G      1.086      0.682      1.056         63        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.3it/s 14.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.7it/s 1.9s\n","                   all        130        668       0.93      0.886      0.927      0.674\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K    109/120      3.98G      1.136      0.731      1.091        105        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.3it/s 14.1s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.9it/s 1.7s\n","                   all        130        668      0.932      0.884      0.929      0.672\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K    110/120      3.98G      1.098     0.6962      1.065        113        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.5it/s 13.4s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.2it/s 2.3s\n","                   all        130        668      0.887      0.916      0.933      0.674\n","Closing dataloader mosaic\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K    111/120      3.98G      1.045     0.6847      1.051         35        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.3it/s 14.7s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.0it/s 1.7s\n","                   all        130        668      0.865      0.889      0.911      0.654\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K    112/120      3.98G      1.038     0.6608      1.029         59        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.6it/s 12.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.7it/s 1.9s\n","                   all        130        668      0.852      0.904      0.906      0.645\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K    113/120      3.98G      1.018     0.6405       1.03         26        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.7it/s 12.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.9it/s 1.7s\n","                   all        130        668      0.845      0.906      0.902       0.65\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K    114/120      3.98G      1.014     0.6131      1.033         36        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.7it/s 12.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.7it/s 1.9s\n","                   all        130        668      0.839        0.9      0.905      0.655\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K    115/120      3.98G      0.984     0.5945      1.018         33        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.7it/s 12.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.8it/s 1.8s\n","                   all        130        668      0.846      0.891      0.906      0.656\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K    116/120      3.98G          1     0.6144      1.024         66        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.7it/s 12.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.9it/s 1.7s\n","                   all        130        668      0.845      0.886      0.904      0.659\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K    117/120      3.98G     0.9979     0.6017      1.022         70        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.7it/s 12.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.8it/s 1.8s\n","                   all        130        668      0.843       0.89      0.903      0.658\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K    118/120      3.98G      1.008     0.6062      1.031         43        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.7it/s 12.1s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.9it/s 1.7s\n","                   all        130        668       0.85      0.889      0.908       0.66\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K    119/120      3.99G     0.9861      0.582      1.015         41        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.8it/s 11.7s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.6it/s 1.9s\n","                   all        130        668      0.846      0.894      0.908      0.658\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K    120/120      4.01G      1.005     0.5848      1.014         43        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 2.9it/s 11.5s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.5it/s 2.0s\n","                   all        130        668      0.845      0.901      0.912      0.661\n","\n","120 epochs completed in 0.564 hours.\n","Optimizer stripped from /content/drive/My Drive/YOLO_NWPU_VHR10/Training_Runs/NWPU_VHR10_yolov5_balanced_materialized/weights/last.pt, 18.5MB\n","Optimizer stripped from /content/drive/My Drive/YOLO_NWPU_VHR10/Training_Runs/NWPU_VHR10_yolov5_balanced_materialized/weights/best.pt, 18.5MB\n","\n","Validating /content/drive/My Drive/YOLO_NWPU_VHR10/Training_Runs/NWPU_VHR10_yolov5_balanced_materialized/weights/best.pt...\n","Ultralytics 8.3.223 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv5s summary (fused): 84 layers, 9,115,406 parameters, 0 gradients, 23.8 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 1.9it/s 2.6s\n","                   all        130        668       0.94      0.882      0.936      0.679\n","              airplane         16        118      0.974      0.992       0.99      0.701\n","                  ship          8         52      0.937      0.865      0.946      0.697\n","          storage tank          3         94      0.937          1      0.992      0.754\n","      baseball diamond         37         69      0.931      0.976      0.988      0.804\n","          tennis court         20        106      0.761      0.774      0.719      0.554\n","      basketball court         17         26      0.955      0.962      0.983      0.766\n","    ground track field         39         39      0.972          1      0.995      0.812\n","                harbor          9         67      0.948       0.82      0.863      0.609\n","                bridge         11         19          1      0.578      0.907      0.453\n","               vehicle         15         78      0.985      0.851      0.972      0.637\n","Speed: 0.2ms preprocess, 5.0ms inference, 0.0ms loss, 3.1ms postprocess per image\n","Results saved to \u001b[1m/content/drive/My Drive/YOLO_NWPU_VHR10/Training_Runs/NWPU_VHR10_yolov5_balanced_materialized\u001b[0m\n","\n","Training finished.\n","Saved best model: /content/drive/My Drive/YOLO_NWPU_VHR10/Models/yolov5_nwpu_vhr_10_best_balanced.pt\n"]}]},{"cell_type":"code","source":["import yaml\n","\n","yaml_path = \"/content/drive/My Drive/YOLO_NWPU_VHR10/NWPU_VHR-10_YOLO_Format/dataset_balanced.yaml\"\n","\n","with open(yaml_path, \"r\") as f:\n","    data = yaml.safe_load(f)\n","\n","# ‚úÖ Fix all paths\n","data[\"path\"] = \"/content/drive/My Drive/YOLO_NWPU_VHR10/NWPU_VHR-10_YOLO_Format\"\n","data[\"train\"] = f\"{data['path']}/images/train\"\n","data[\"val\"] = f\"{data['path']}/images/val\"\n","\n","# Save the updated YAML\n","with open(yaml_path, \"w\") as f:\n","    yaml.safe_dump(data, f, sort_keys=False)\n","\n","print(\"‚úÖ YAML paths fixed:\")\n","print(yaml.dump(data, sort_keys=False))\n"],"metadata":{"id":"pUAs4YhZ88to","executionInfo":{"status":"ok","timestamp":1762013581494,"user_tz":-330,"elapsed":15,"user":{"displayName":"Manvi Sharma","userId":"13719445681117001639"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d090e1cc-7501-4d36-907d-ef47b43135fa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ YAML paths fixed:\n","path: /content/drive/My Drive/YOLO_NWPU_VHR10/NWPU_VHR-10_YOLO_Format\n","train: /content/drive/My Drive/YOLO_NWPU_VHR10/NWPU_VHR-10_YOLO_Format/images/train\n","val: /content/drive/My Drive/YOLO_NWPU_VHR10/NWPU_VHR-10_YOLO_Format/images/val\n","nc: 10\n","names:\n","- airplane\n","- ship\n","- storage tank\n","- baseball diamond\n","- tennis court\n","- basketball court\n","- ground track field\n","- harbor\n","- bridge\n","- vehicle\n","\n"]}]},{"cell_type":"code","source":["# ==========================================================================\n","# CELL 8: EXTRACT AND SAVE TRAINING METRICS\n","# ==========================================================================\n","\"\"\"\n","Extract training metrics (loss, precision, recall, mAP) from the results\n","and save them as CSV files for analysis.\n","\"\"\"\n","\n","import pandas as pd\n","import json\n","from pathlib import Path\n","import shutil\n","\n","print(\"=\"*80)\n","print(\"EXTRACTING AND SAVING TRAINING METRICS\")\n","print(\"=\"*80)\n","\n","# Paths\n","runs_dir = Path('/content/drive/My Drive/YOLO_NWPU_VHR10/Training_Runs')\n","results_dir = Path('/content/drive/My Drive/YOLO_NWPU_VHR10/Results')\n","\n","# Find the latest run\n","run_dirs = sorted(runs_dir.glob('**/'), key=lambda x: x.stat().st_mtime, reverse=True)\n","latest_run = None\n","for run_dir in run_dirs:\n","    if (run_dir / 'weights').exists():\n","        latest_run = run_dir\n","        break\n","\n","if latest_run is None:\n","    print(\"‚úó No completed training runs found!\")\n","    print(\"  Please run CELL 7 first!\")\n","else:\n","    print(f\"‚úì Found latest run: {latest_run.name}\")\n","\n","    # Look for results.csv (YOLOv8 saves training metrics here)\n","    results_csv_path = latest_run / 'results.csv'\n","    if results_csv_path.exists():\n","        print(f\"\\n1. Loading training metrics from {results_csv_path.name}...\")\n","        # Load results CSV\n","        df_results = pd.read_csv(results_csv_path)\n","        # Clean column names (remove leading/trailing spaces)\n","        df_results.columns = df_results.columns.str.strip()\n","        print(f\"   ‚úì Loaded {len(df_results)} epochs of training data\")\n","        print(f\"   ‚úì Columns: {list(df_results.columns)}\")\n","\n","        # Display summary statistics\n","        print(f\"\\n2. Training Summary:\")\n","        print(f\"   Total Epochs: {len(df_results)}\")\n","\n","        # Try to extract key metrics\n","        metric_columns = {\n","            'train_loss': ['train/box_loss', 'box_loss'],\n","            'val_loss': ['val/box_loss', 'box_loss'],\n","            'precision': ['metrics/precision(B)', 'precision'],\n","            'recall': ['metrics/recall(B)', 'recall'],\n","            'mAP50': ['metrics/mAP50(B)', 'mAP50'],\n","            'mAP50_95': ['metrics/mAP50-95(B)', 'mAP50-95'],\n","        }\n","        for metric_name, possible_columns in metric_columns.items():\n","            for col in possible_columns:\n","                if col in df_results.columns:\n","                    last_value = df_results[col].iloc[-1]\n","                    print(f\"   ‚Ä¢ Final {metric_name}: {last_value:.6f}\")\n","                    break\n","\n","        # Save metrics to results directory\n","        print(f\"\\n3. Saving metrics to Results directory...\")\n","        # Save full results\n","        results_save_path = results_dir / 'nwpu_vhr10_training_metrics.csv'\n","        df_results.to_csv(results_save_path, index=False)\n","        print(f\"   ‚úì Saved: {results_save_path}\")\n","\n","        # Save summary statistics\n","        summary_dict = {}\n","        summary_dict['Total Epochs'] = len(df_results)\n","        for metric_name, possible_columns in metric_columns.items():\n","            for col in possible_columns:\n","                if col in df_results.columns:\n","                    summary_dict[f'Final {metric_name}'] = df_results[col].iloc[-1]\n","                    summary_dict[f'Best {metric_name}'] = df_results[col].max() if 'loss' not in metric_name else df_results[col].min()\n","                    summary_dict[f'Epoch of Best {metric_name}'] = int(df_results[col].idxmax()) if 'loss' not in metric_name else int(df_results[col].idxmin())\n","                    break\n","        summary_df = pd.DataFrame([summary_dict])\n","        summary_path = results_dir / 'nwpu_vhr10_training_summary.csv'\n","        summary_df.to_csv(summary_path, index=False)\n","        print(f\"   ‚úì Saved: {summary_path}\")\n","\n","        # Also save the validation results\n","        val_results_path = latest_run / 'weights' / 'best.pt'\n","        if val_results_path.exists():\n","            print(f\"\\n4. Model Information:\")\n","            print(f\"   ‚úì Best model: {val_results_path}\")\n","            print(f\"     Size: {val_results_path.stat().st_size / 1e6:.2f} MB\")\n","    else:\n","        print(f\"‚úó results.csv not found in {latest_run}\")\n","        print(f\"  Available files: {list(latest_run.glob('*.*'))}\")\n","\n","print(\"\\n‚úì Metrics extraction completed!\")\n"],"metadata":{"id":"B6WfxsJY7qoP","executionInfo":{"status":"ok","timestamp":1762013582814,"user_tz":-330,"elapsed":1319,"user":{"displayName":"Manvi Sharma","userId":"13719445681117001639"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"202e44de-ea7a-4a9a-9f10-5af408f2b197"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["================================================================================\n","EXTRACTING AND SAVING TRAINING METRICS\n","================================================================================\n","‚úì Found latest run: NWPU_VHR10_yolov5_balanced_materialized\n","\n","1. Loading training metrics from results.csv...\n","   ‚úì Loaded 120 epochs of training data\n","   ‚úì Columns: ['epoch', 'time', 'train/box_loss', 'train/cls_loss', 'train/dfl_loss', 'metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)', 'val/box_loss', 'val/cls_loss', 'val/dfl_loss', 'lr/pg0', 'lr/pg1', 'lr/pg2']\n","\n","2. Training Summary:\n","   Total Epochs: 120\n","   ‚Ä¢ Final train_loss: 1.005300\n","   ‚Ä¢ Final val_loss: 1.075940\n","   ‚Ä¢ Final precision: 0.844720\n","   ‚Ä¢ Final recall: 0.901280\n","   ‚Ä¢ Final mAP50: 0.912080\n","   ‚Ä¢ Final mAP50_95: 0.660960\n","\n","3. Saving metrics to Results directory...\n","   ‚úì Saved: /content/drive/My Drive/YOLO_NWPU_VHR10/Results/nwpu_vhr10_training_metrics.csv\n","   ‚úì Saved: /content/drive/My Drive/YOLO_NWPU_VHR10/Results/nwpu_vhr10_training_summary.csv\n","\n","4. Model Information:\n","   ‚úì Best model: /content/drive/My Drive/YOLO_NWPU_VHR10/Training_Runs/NWPU_VHR10_yolov5_balanced_materialized/weights/best.pt\n","     Size: 18.53 MB\n","\n","‚úì Metrics extraction completed!\n"]}]},{"cell_type":"code","source":["# ==========================================================================\n","# CELL 9: VALIDATE MODEL ON VALIDATION SET & CALCULATE PER-CLASS METRICS\n","# ==========================================================================\n","\"\"\"\n","Validate the trained model on the validation set and extract per-class\n","metrics for analysis and comparison.\n","\"\"\"\n","\n","from ultralytics import YOLO\n","import pandas as pd\n","from pathlib import Path\n","import json\n","\n","print(\"=\"*80)\n","print(\"VALIDATING MODEL ON VALIDATION SET\")\n","print(\"=\"*80)\n","\n","# Paths\n","models_dir = Path('/content/drive/My Drive/YOLO_NWPU_VHR10/Models')\n","dataset_processed_dir = Path('/content/drive/My Drive/YOLO_NWPU_VHR10/NWPU_VHR-10_YOLO_Format')\n","results_dir = Path('/content/drive/My Drive/YOLO_NWPU_VHR10/Results')\n","yaml_path = dataset_processed_dir / 'dataset.yaml'\n","\n","# Best model path\n","best_model_path = models_dir / 'yolov5_nwpu_vhr_10_best_balanced.pt'\n","if not best_model_path.exists():\n","    print(f\"‚úó Best model not found at {best_model_path}\")\n","    print(\"  Please run CELL 7 first!\")\n","else:\n","    print(f\"‚úì Loading best model: {best_model_path.name}\")\n","\n","    # Load trained model\n","    model = YOLO(str(best_model_path))\n","\n","    print(\"\\n1. Running validation...\")\n","    # Validate model\n","    val_results = model.val(\n","        data=str(yaml_path),\n","        split='val',\n","        imgsz=640,\n","        batch=16,\n","        verbose=True,\n","        save_json=True,  # Save results as JSON\n","    )\n","\n","    print(\"\\n2. Validation completed!\")\n","\n","    # Extract overall metrics\n","    print(f\"\\n3. Overall Metrics:\")\n","    print(f\"   mAP@50: {val_results.box.map50:.4f}\")\n","    print(f\"   mAP@50:95: {val_results.box.map:.4f}\")\n","    print(f\"   Precision: {val_results.box.mp:.4f}\")\n","    print(f\"   Recall: {val_results.box.mr:.4f}\")\n","\n","    # Create overall metrics DataFrame\n","    overall_metrics = {\n","        'Model': 'YOLOv5 Small (NWPU VHR-10)',\n","        'mAP@50': val_results.box.map50,\n","        'mAP@50:95': val_results.box.map,\n","        'Precision': val_results.box.mp,\n","        'Recall': val_results.box.mr,\n","        'F1_Score': 2 * (val_results.box.mp * val_results.box.mr) / (val_results.box.mp + val_results.box.mr + 1e-9),\n","    }\n","    overall_df = pd.DataFrame([overall_metrics])\n","    overall_metrics_path = results_dir / 'nwpu_vhr10_overall_metrics.csv'\n","    overall_df.to_csv(overall_metrics_path, index=False)\n","    print(f\"\\n   ‚úì Saved: {overall_metrics_path}\")\n","\n","    # Extract per-class metrics (if available)\n","    print(f\"\\n4. Per-Class Metrics:\")\n","    class_names = [\n","        'airplane', 'ship', 'storage tank', 'baseball diamond', 'tennis court',\n","        'basketball court', 'ground track field', 'harbor', 'bridge', 'vehicle'\n","    ]\n","\n","    # YOLOv8 provides class-wise statistics\n","    if hasattr(val_results.box, 'maps'):\n","        per_class_data = []\n","        for class_id, class_name in enumerate(class_names):\n","            if class_id < len(val_results.box.maps):\n","                map_value = val_results.box.maps[class_id]\n","                per_class_data.append({\n","                    'Class': class_name,\n","                    'Class_ID': class_id,\n","                    'AP@50': map_value,\n","                })\n","                print(f\"   {class_name:20s}: AP@50 = {map_value:.4f}\")\n","        if per_class_data:\n","            per_class_df = pd.DataFrame(per_class_data)\n","            per_class_metrics_path = results_dir / 'nwpu_vhr10_per_class_metrics.csv'\n","            per_class_df.to_csv(per_class_metrics_path, index=False)\n","            print(f\"\\n   ‚úì Saved: {per_class_metrics_path}\")\n","\n","print(\"\\n‚úì Validation completed successfully!\")\n"],"metadata":{"id":"zAVLlooI7zUZ","executionInfo":{"status":"ok","timestamp":1762013594539,"user_tz":-330,"elapsed":11722,"user":{"displayName":"Manvi Sharma","userId":"13719445681117001639"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b602bc09-6c58-4d13-9869-8a5769322ac9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["================================================================================\n","VALIDATING MODEL ON VALIDATION SET\n","================================================================================\n","‚úì Loading best model: yolov5_nwpu_vhr_10_best_balanced.pt\n","\n","1. Running validation...\n","Ultralytics 8.3.223 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n","YOLOv5s summary (fused): 84 layers, 9,115,406 parameters, 0 gradients, 23.8 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 3.0¬±1.6 ms, read: 6.4¬±8.1 MB/s, size: 94.8 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/My Drive/YOLO_NWPU_VHR10/NWPU_VHR-10_YOLO_Format/labels/val.cache... 130 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 130/130 54.8Kit/s 0.0s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 1.6it/s 5.8s\n","                   all        130        668      0.923      0.875      0.933      0.676\n","              airplane         16        118      0.974      0.992       0.99      0.698\n","                  ship          8         52      0.909      0.865      0.951      0.688\n","          storage tank          3         94       0.94      0.996      0.992      0.746\n","      baseball diamond         37         69      0.931      0.973      0.989      0.812\n","          tennis court         20        106      0.763      0.774      0.717      0.551\n","      basketball court         17         26      0.934      0.962      0.984      0.771\n","    ground track field         39         39      0.973          1      0.995      0.817\n","                harbor          9         67      0.926      0.791      0.847      0.596\n","                bridge         11         19       0.89      0.579      0.894      0.462\n","               vehicle         15         78       0.99      0.821      0.973      0.621\n","Speed: 2.9ms preprocess, 10.2ms inference, 0.0ms loss, 5.6ms postprocess per image\n","Saving /content/runs/detect/val/predictions.json...\n","Results saved to \u001b[1m/content/runs/detect/val\u001b[0m\n","\n","2. Validation completed!\n","\n","3. Overall Metrics:\n","   mAP@50: 0.9331\n","   mAP@50:95: 0.6761\n","   Precision: 0.9228\n","   Recall: 0.8752\n","\n","   ‚úì Saved: /content/drive/My Drive/YOLO_NWPU_VHR10/Results/nwpu_vhr10_overall_metrics.csv\n","\n","4. Per-Class Metrics:\n","   airplane            : AP@50 = 0.6976\n","   ship                : AP@50 = 0.6880\n","   storage tank        : AP@50 = 0.7459\n","   baseball diamond    : AP@50 = 0.8119\n","   tennis court        : AP@50 = 0.5506\n","   basketball court    : AP@50 = 0.7709\n","   ground track field  : AP@50 = 0.8173\n","   harbor              : AP@50 = 0.5962\n","   bridge              : AP@50 = 0.4622\n","   vehicle             : AP@50 = 0.6208\n","\n","   ‚úì Saved: /content/drive/My Drive/YOLO_NWPU_VHR10/Results/nwpu_vhr10_per_class_metrics.csv\n","\n","‚úì Validation completed successfully!\n"]}]}]}